---
title: "Statistiques et data mining"
subtitle: "Master Hydrosystèmes et Bassins Versants"
author: "Louis Manière"
institute: "Université de Tours"
date: last-modified
license: "code : MIT License, presentation : CC BY-NC"
lang: "fr"
format: 
  revealjs:
    navigation-mode: vertical
    theme: custom.scss
    logo: "./img/universite-tours-logo.png"
    footer: "Master 1 Hydrosystèmes et Bassins Versants 2024-2025"
    css: custom.css
    slide-number: true
    show-slide-number: all
    smaller: false
    chalkboard: true
    margin: 0.2
    width: 1150
    df-print: kable
editor: visual
---

# Introduction

## Les statistiques

L'ensemble des méthodes qui ont pour objet la collecte, le traitement et l'interprétation de données d'observation relatives à un groupe d'individus ou d'unités.

- Statistique descriptive : Décrire, résumer, visualiser des données.
- Statistique inférentielle (Inférence statistique) : induire des caractéristiques sur une population à partir d'un échantillon (relation, distribution).

## Population ou échantillon ?

- **Population** : ensemble des individus ou unités statistiques sur lesquels on veut faire des observations.
- **Echantillon** : sous-ensemble de la population, choisi de manière aléatoire ou non, qui permet de faire des observations.

Sélection de tous les bruns de la salle, population ou échantillon ?

![](./img/population_echantillon.png){fig-align="center"}

## Le data mining

L'exploration et l'analyse de base de données pour le résumer, détecter des règles, des tendances, des associations ou des structures particulières. L'exploration des bases de données existantes en géosciences peut être utilisée pour détecter des nouvelles tendances ou comportements dans des milieux ou bien préparer une étude avant de une campagne de mesure.

## Objectifs du cours {.smaller}

- Apprendre à décrire un jeu de données, le synthétiser pour mettre en évidence les informations pertinentes qu'il contient et ses limites pour répondre à certaines questions.

- Pourvoir créer de nouvelles informations à partir de relations ou comportements identifiés dans les données. Utiliser ces informations pour prédire de nouvelles données et identifier communauté d'individus communs ou différents.

- Acquérir des outils de manipulation, description et d'analyse de données.

- Avoir une démarche critique sur les données, les outils statistiques et les résultats obtenus.

## R et RStudio

::: columns
::: {.column width="50%"}

- Un logiciel et language de développement très complet, gratuit et open source avec une communauté active. 
- Permet de reproduire et partager facilement les analyses. 
- Un début apprentissage un peu plus difficile que des logiciels "clé en main".
:::

::: {.column width="50%"}
![](./img/Rscary.png){width="100%"} [^1]
:::
:::

[^1]: Artwork by @allison_horst.

## Ressources et sources du cours {.smaller}

- [Les statistiques pour statophobes (2004), Denis Poinsot](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf)
- Data Mining et Statistique décisionnelle (2017), Stéphane Tufféry, Editions Technip
- [Analyse-R, Joseph Larmarange - Université Paris Cité, IRD](https://larmarange.github.io/analyse-R/)
- [Guide-R, Joseph Larmarange - Université Paris Cité, IRD](https://larmarange.github.io/guide-R/)
- [Grimoire, Lise Vaudor, CNRS](http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/intro.html)
- [Cours d'Eric Marcon, Agro Paris Tech](https://ericmarcon.github.io/Cours-R-Geeft/)
- [Cours d'Antoine Massé, IUT de Bordeaux](https://sites.google.com/site/rgraphiques/home)
- [R for datascience, Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund](https://r4ds.hadley.nz/)
- [Formation ministérielle à R et aux sciences des données](https://mtes-mct.github.io/parcours-r/)
- [Vidéos d'Eric Lombardot - Université Paris 1 Panthéon Sorbonne](https://www.youtube.com/@EricLombardot)
Pour éviter R studio : 
- [Logiciel Jamovi](https://www.jamovi.org/)
- [Logiciel Rattle](https://github.com/gjwgit/rattleng)
  
## Plan du cours

- Introduction
- Statistiques univariées
- Statistiques bivariées
- La comparaison de jeux de données
- Statistiques multivariées ou  multimentionnelles
- Classification

## Données utilisées

- Données hydromorphologiques issus du protocole CARHYCE (Agence Française de la Biodiversité), disponible sur [IED CARHYCE](https://analytics.huma-num.fr/ied_carhyce/)
  - Mesure de morphologie du lit, de granulométrie, de débit et de ripisylve.
  - Des données enrichies par des estimations à plein bord et les surfaces des bassins versant.
  - Plus de 2000 stations de mesures.

## Installation des (nombreux?) packages

```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
# install all necessary packages
install.packages(c("ggplot2", "dplyr", "tidyr", "tibble", 
                   "janitor", "skimr", "dataMaid", "plotly", 
                   "e1071", "gmodels", "ggpmisc", "nortest", 
                   "FactoMineR", "factoextra", "gtsummary", 
                   "explor", "boot", "qqplotr", "corrplot"))
```


## Importons les pakages du cours

```{r, echo=TRUE, collapse=FALSE, results='hide'}
library(ggplot2) # Graphics
library(dplyr) # Data manipulation
library(tidyr) # Data cleaning
library(tibble) # Table visualisation
library(janitor) # Column names cleaning
library(skimr) # Data summary
library(dataMaid) # Data report
library(plotly) # Interactive plots
library(e1071) # Skewness
library(gmodels) # Contingency tables
library(ggpmisc) # Regression line
library(nortest) # Normality tests
library(FactoMineR) # Factorial analysis
library(factoextra) # Factorial analysis
library(gtsummary) # Regression summary
library(explor) # Data exploration
library(boot) # Bootstrap
library(qqplotr) # QQ-plot
library(corrplot) # Correlation plot
```

## Explorons le jeu de données

```{r, echo=TRUE, collapse=FALSE, results='hide'}
# import dataset
carhyce_brute <- read.csv("data/Operations_CARHYCE_2024-06-25.csv",
                  sep=";",dec=",",header=TRUE, encoding = "utf-8")
```

```{r, echo=TRUE, collapse=FALSE}
print(as_tibble(head(carhyce_brute)))
```


## Dimensions et variables

```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
names(carhyce_brute) # variable names
class(carhyce_brute) # table type (data.frame)
dim(carhyce_brute)   # table dimension
str(carhyce_brute)   # variable type
```

```{r, echo=TRUE, collapse=FALSE}
print(str(carhyce_brute))
```

## Les données quantitatives

![](./img/datatype_quantitative.png){width="60%" fig-align="center"} [^2]

[^2]: Artwork by @allison_horst.

## Les données qualitatives

![](./img/datatype_qualitative.png){width="80%" fig-align="center"} [^3]

[^3]: Artwork by @allison_horst.

## Nettoyage des colonnes

```{r, echo=TRUE, collapse=FALSE}
# clean column names with janitor
carhyce <- carhyce_brute %>% # %>% = pipe operator from dplyr |> for native pipe
  clean_names() # clean column  names
print(names(carhyce))
```

# Statistiques univariées

## Objectifs

- Description des types de variables
- Analyse de la distribution (graphiques et paramètres)
- Discrétisation de variables quantitatives
- Détection et traitement des valeurs extrêmes
- Comparaison à la loi normale

## nettoyage des lignes et sélection des variables

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date
  ungroup() %>%  # ungroup data
  select(surface_bv_km2, continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite, classe_ripisylve,
         nom_her_ou_dom_dominant, debit_plein_bord_m3_s,
         largeur_mouillee_qb_m) # select columns
print(head(carhyce_stat))
```

## Synthèse analyses univariées

![](./img/datatype_summary.png){width="100%" fig-align="center"}

## Distribution des bassins versants des stations

```{r, echo=TRUE, collapse=FALSE}
summary(carhyce_stat$surface_bv_km2)
```

::: columns
::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Histogram
hist(carhyce_stat$surface_bv_km2, 
     main = "Surfaces de bassins versants", 
     xlab = "Surface de bassins versants (km2)", col = "lightblue")
```
:::

::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Boxplot
boxplot(carhyce_stat$surface_bv_km2, 
        main = "Surfaces de bassins versants", 
        ylab = "Surface de bassins versants (km2)", col = "lightblue")
points(1,mean(carhyce_stat$surface_bv_km2,na.rm=T),pch=16,col="red")
```
:::
:::

## Discrétiser une variable quantitative {.smaller}

- **Règle de Sturges** : méthode de détermination du nombre de classes à utiliser dans un histogramme => avoir un nombre de classes qui soit à la fois suffisamment grand pour capturer la structure de la distribution des données, mais pas trop grand pour ne pas perdre de sensibilité dans la visualisation.

- En pratique, il est souvent recommandé de tester plusieurs nombres de classes et de choisir celui qui offre la meilleure représentation visuelle des données tout en préservant leur structure.

- Autres méthodes : 
    - Effectifs égaux : par exemple les quantiles
    - Intervalles égaux : par exemple une classe toute les X unités
    - Par seuil de valeurs : par exemple les classes de granulométrie

## Discrétisation "manuelle" par la règle de Sturges

```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
bins <- nclass.Sturges(carhyce_stat$largeur_mouillee_qb_m) # set breaks with Sturges
carhyce_stat$largeur_mouillee_qb_m_sturges <- cut(carhyce_stat$largeur_mouillee_qb_m, 
                                                  breaks = bins, 
                                                  include.lowest = TRUE, 
                                                  right = FALSE) # new column with breaks
```

## Changement de discrétisation et outliers

```{r, echo=TRUE, collapse=FALSE, warning=FALSE, fig.align='center', fig.height=4}
# plotly interactive histogram with 1000 breaks
plot_ly(x = carhyce_stat$surface_bv_km2, type = "histogram", nbinsx = 1000)
```

## Les outliers

- Valeurs extrêmes qui ne suivent pas la distribution générale des données.
- Peuvent être des erreurs de mesure, des valeurs aberrantes ou des valeurs extrêmes.
- Peuvent fausser les résultats des analyses statistiques qui ne seront plus représentatives de la population.
- Rend la lecture et l'interprétation des graphiques difficiles.

## Retrait des valeurs extrêmes

```{r, echo=TRUE, collapse=FALSE}
# keep the data below the 90th percentile and above 0
carhyce_stat <- carhyce_stat %>% 
  filter(surface_bv_km2 < quantile(carhyce_stat$surface_bv_km2, 0.90, na.rm = TRUE)) %>% 
  filter(surface_bv_km2 > 0)
```

::: columns
::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Histogram with normal curve
h <- hist(carhyce_stat$surface_bv_km2, col = "lightblue", 
          main = "Surface des bassins versants", 
          xlab = "Surface de bassins versants (km2)") 
xfit <- seq(min(carhyce_stat$surface_bv_km2),
            max(carhyce_stat$surface_bv_km2), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat$surface_bv_km2), sd = sd(carhyce_stat$surface_bv_km2)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat$surface_bv_km2) 
lines(xfit, yfit, col = "red", lwd = 2)
```
:::

::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Boxplot
boxplot(carhyce_stat$surface_bv_km2, 
        main = "Surfaces de bassins versants", 
        ylab = "Surface de bassins versants (km2)", 
        col = "lightblue", range = 0)
points(1,mean(carhyce_stat$surface_bv_km2,na.rm=T),pch=16,col="red")
```
:::
:::

## Loi normale ou loi de Gauss {.smaller}

-  Distribution symétrique centrée sur la moyenne dont la forme est déterminée par l'écart-type.

Définie par une fonction de probabilité :

- Environ 68% des valeurs sont comprises entre $\mu - \sigma$ et $\mu + \sigma$.
- 95% des valeurs sont comprises entre $\mu - 1.96\sigma$ et $\mu + 1.96\sigma$.

- Très utilisées dans les tests statistiques ou la description de phénomènes aléatoires.

```{r, echo=FALSE, collapse=FALSE, fig.align='center'}
# several density plots on the same graph with dnorm
x <- seq(-4, 4, length=100)
hx <- dnorm(x, mean=0, sd=1)
hx2 <- dnorm(x, mean=-0.5, sd=0.7)
hx3 <- dnorm(x, mean=0.5, sd=0.5)
plot(x, hx, type="l", lwd=2, col="black", xlab="x", ylab="Density", main="Density de distributions normale", ylim=c(0,0.8), xlim=c(-5,5))
lines(x, hx2, lwd=2, col="red")
lines(x, hx3, lwd=2, col="blue")
```
## Niveau de dissymétrie

\

![](./img/normality.png){width="100%" fig-align="center"}

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- rnorm(1000, mean = 0, sd = 1)  # Generate 1000 samples
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- rweibull(1000, shape = 30, scale = 2)  # Generate 1000 samples
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- data_lognormal <- rlnorm(1000, meanlog = 2, sdlog = 0.8)
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```


## Coefficient d'assymétrie de Fisher

```{r, echo=TRUE, collapse=FALSE}
# skewness
e1071::skewness(carhyce_stat$surface_bv_km2, na.rm = TRUE, type = 1) # type 1 = Fisher
```

![](./img/skewness.png){width="100%" fig-align="center"}

## Coefficient d'aplatissement de Fisher

```{r, echo=TRUE, collapse=FALSE}
# kurtosis
e1071::kurtosis(carhyce_stat$surface_bv_km2, na.rm = TRUE, type = 1) # type 1 = Fisher
```

![](./img/kurtosis.png){width="100%" fig-align="center"}

## QQ-plot ou diagramme quantile-quantile

On compare les quantiles de la distribution observée et ceux de la distribution théorique (ici la loi normale).

```{r, echo=TRUE, collapse=FALSE, fig.height=4, fig.align='center'}
# QQ-plot
ggplot(data = carhyce_stat, mapping = aes(sample = surface_bv_km2)) +
  stat_qq_band() +
  stat_qq_line() +
  stat_qq_point() +
  labs(title = "QQ-plot de la surface des bassins versants", x = "Quantiles théoriques", y = "Quantiles observés")
```

## Vous avez dit tests statistiques ? {.smaller}

Partons d'une hypothèse :

- $H_0$ : la distribution suit une loi normale.

On va comparer la distribution de nos données à une distribution théorique (ici la loi normale) pour déterminer si on peut rejeter $H_0$.
Le test de Shapiro-Wilk utilise la position des quantile pour déterminer si la distribution suit une loi normale, un peu comme pour le QQ-plot. On prend la position des valeurs de nos données triées pour calculer leur équivalent projecté dans une distribution normale et les résultat attendus si $H_0$ est vrai qui n'ont presque aucune chance d'être obtenu.

- $H_0$ est rejetée si les valeurs de nos données ont presque aucune chance d'être obtenues si la distribution était normale. Presque aucune chance est généralement <5% de chance, noté p-value (seuil de significativité) < 0.05.
- $H_0$ n'est pas rejetée si les valeurs de nos données ont une chance (même modeste) d'être obtenues si la distribution était normale.

La p-value est la probabilité de se tromper en rejetant $H_0$.


::: aside
Cette explication des tests est reprise de l'ouvrage de Denis Poinsot "Les statistiques pour les statophobes" (2004) disponible gratuitement [ici](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf)
:::

## Test de normalité - précaution / utilisation

- Les tests de normalité sont sensibles à la taille de l'échantillon : 
    - Pour un échantillon de taille réduite, les tests de normalité peuvent être biaisés.
    - Pour un échantillon de taille importante, les tests de normalité peuvent être trop sensibles.

- Souvent utilisé au prélable d'autres tests statistiques dit paramétriques : 
  - Shapiro-Wilk => meilleur pour de petits échantillons (<2000).
  - Kolmogorov-Smirnov => grands échantillons (>2000).
  - Anderson-Darling => grands échantillons (>2000).


## Test de normalité

::: panel-tabset

### Shapiro-Wilk
```{r, echo=TRUE, collapse=FALSE}
shapiro.test(carhyce_stat$surface_bv_km2)
```

### Anderson-Darling
```{r, echo=TRUE, collapse=FALSE}
ad.test(carhyce_stat$surface_bv_km2)
```

### Kolmogorov-Smirnov
```{r, echo=TRUE, collapse=FALSE}
ks.test(carhyce_stat$surface_bv_km2, "pnorm", mean = mean(carhyce_stat$surface_bv_km2), sd = sd(carhyce_stat$surface_bv_km2))
```
:::

- $H_0$ : la variable suit une distribution normale.
- $H_1$ : la variable ne suit pas une distribution normale.

- On peut rejeter $H_0$ et valider $H_1$ avec une probabilité de se tromper de $2.2 \times 10^{-14} \times 100$%.

- **Ou** (*moins bien*) p-value $<$ 0.05 => la distribution ne suit pas une loi normale.

## Distribution des classes de ripisylve

```{r, echo=TRUE, collapse=FALSE}
# Table
print(table(carhyce_stat$classe_ripisylve))
```

```{r, echo=TRUE, collapse=FALSE}
# Create a frequency table
freq_table <- carhyce_stat %>%
  group_by(classe_ripisylve) %>%
  summarise(count = n()) %>%
  mutate(freq_percent = count / sum(count) * 100,
         cum_freq = cumsum(count),
         cum_freq_percent = cumsum(freq_percent))
print(freq_table)
```

## Diagramme en secteur

```{r, echo=TRUE, collapse=FALSE}
# Pie chart
pie(table(carhyce_stat$classe_ripisylve), main = "Répartition des classes de ripisylve")
```

## Cheat code exploration de données

```{r, echo=TRUE, collapse=FALSE}
print(skim(carhyce_stat$surface_bv_km2))
```

```{r, echo=TRUE, collapse=FALSE, results='hide'}
# makeDataReport(carhyce_stat)
```

# Statistiques bivariées

## Objectifs

- Pouvoir décrire la relation qui peut exister entre deux variables.
- Utiliser les bons outils selon la nature des variables à comparer.
- Evaluer le type, l'intensité et le sens d'une relation entre deux variables qauntitatives.

## Reprenons nos données

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  filter(surface_bv_km2 < quantile(carhyce$surface_bv_km2, 0.90, na.rm = TRUE)) %>% # keep surface_bv_km2 data below the 90th percentile
  filter(debit_plein_bord_m3_s < quantile(carhyce$debit_plein_bord_m3_s, 0.95, na.rm = TRUE)) %>%
  filter(largeur_mouillee_qb_m < quantile(carhyce$largeur_mouillee_qb_m, 0.975, na.rm = TRUE)) %>%
  filter(vitesse_moyenne_qb_m_s < quantile(carhyce$vitesse_moyenne_qb_m_s, 0.975, na.rm = TRUE)) %>%
  filter(d50_mm < quantile(carhyce$d50_mm, 0.99, na.rm = TRUE)) %>%
  # group categories continuite_ripisylve_rive_gauche and continuite_ripisylve_rive_droite :"espacée" = "bosquets éparses" + "espacée-régulière" + "isolée"
  mutate(continuite_ripisylve_rive_gauche = ifelse(continuite_ripisylve_rive_gauche %in% c("bosquets éparses", "espacée-régulière", "isolée"), "espacée", continuite_ripisylve_rive_gauche),
         continuite_ripisylve_rive_droite = ifelse(continuite_ripisylve_rive_droite %in% c("bosquets éparses", "espacée-régulière", "isolée"), "espacée", continuite_ripisylve_rive_droite)) %>%
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         debit_plein_bord_m3_s,
         largeur_mouillee_qb_m,
         vitesse_moyenne_qb_m_s,
         d50_mm,
         nombre_transect) # select columns
```

## Qualitatif VS qualitatif - Tableau de contingence

![](./img/contingency_table.png){width="100%" fig-align="center"}

[Distribution jointe de deux variables qualitatives (ou quantitatives discrétisées)]{style="font-size: 0.7em;"}

[On compte les individus pour chaque modalité des deux variables]{style="font-size: 0.7em;"}

[Distribution conditionnelle : ]{style="font-size: 0.7em;"}

[   - en ligne : quelle distribution de X des cours d'eau normand]{style="font-size: 0.7em;"}

[   - en colonne : quelle distribution de Y des cours d'eau de bonne qualité]{style="font-size: 0.7em;"}

## Tableau de contingence

::: panel-tabset
### Rbase

```{r, echo=TRUE, collapse=FALSE}
# Rbase method contingency table
tab <- table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite)
tab_mag <- addmargins(tab) # margins (effectifs marginaux)
print(tab_mag)
```

### gmodels effectifs

```{r, echo=TRUE, collapse=FALSE, results='hide'}
contingency_table <- CrossTable(carhyce_stat$continuite_ripisylve_rive_gauche, 
                                 carhyce_stat$continuite_ripisylve_rive_droite, 
                                 prop.chisq = FALSE, prop.t = TRUE, prop.r = TRUE, prop.c = TRUE)
```

```{r, echo=TRUE, collapse=FALSE}
print(contingency_table$t)
```
:::

## Effectif partiels (fréquence)

::: panel-tabset
### total

[Fréquences partielles sur effectif total (le total des fréquences = 1) : X% des individus appartiennent aux modalités truc et bidule **ou**  X % des cours d'eau ont une eau de bonne qualité et sont en Normandie]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite
print(round(contingency_table$prop.tbl, 3)) # or prop.table(x, y)
```

### ligne

[Fréquence partielle sur effectif marginal (fréquence conditionnelle, le total de chaque ligne = 1) : X% des cours d'eau Normands ont une eau de mauvaise qualité]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite
print(round(contingency_table$prop.row, 3)) # or prop.table(x, y, margin = 1)
```

### colonne

[Fréquence partielle sur effectif marginal (fréquence conditionnelle, le total de chaque colonne = 1) : X% des cours d'eau de bonne qualité sont Normands]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite (ou fréquence conditionnelle)
print(round(contingency_table$prop.col, 3)) # or prop.table(x, y, margin = 2)
```
:::

## Diagramme en barre et mosaique

::: panel-tabset
### Groupé

```{r, echo=TRUE, collapse=FALSE, fig.height=4}
ggplot(carhyce_stat, aes(x=factor(continuite_ripisylve_rive_gauche), fill=factor(continuite_ripisylve_rive_droite))) +
  geom_bar(position = "dodge") +
  labs(x = "Ripisylve rive gauche", y = "Effectif", fill = "Ripisylve rive droite") +
  theme_minimal()
```

### Empilé

```{r, echo=TRUE, collapse=FALSE, fig.height=4}
ggplot(carhyce_stat, aes(x=factor(continuite_ripisylve_rive_gauche), fill=factor(continuite_ripisylve_rive_droite))) +
  geom_bar(position = "stack") +
  labs(x = "Ripisylve rive gauche", y = "Effectif", fill = "Ripisylve rive droite") +
  theme_minimal()
```

### Mosaique

```{r, echo=TRUE, collapse=FALSE}
mosaicplot(table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite), xlab = "Rive gauche", ylab = "Rive droite", main = "")
```
:::

## Test du Chi2 d'indépendance

- Vérifier un lien de dépendance statistiquement significatif entre deux variables qualitatives.

- Conditions d'application : 
    - Les variables doivent être qualitatives.
    - Les effectifs combinés des modalités des variables $\geq$ 5 (du moins pour 80% des effectifs joints).
    
- Hypothèses : 
    - $H_0$ : les variables sont indépendantes.
    - $H_1$ : les variables sont dépendantes.

## Chi2 - calcul des effectifs attendus.

Tableau de contingence observé :
```{r}
tab_mag
```
- Quelles sont les effectifs joints attendus si les deux variables sont indépendantes ?

- Les effectifs attendus suivent la distribution marginale des variables pour respecter les répartitions totales de chaque variable.

- La formule est le produit des effectifs marginaux divisé par le total des effectifs.

## Chi2 - calcul des effectifs attendus.

Tableau de contingence observé :
```{r}
tab_mag
```
Exemple : 

- Le nombre de stations avec une ripisyle espacée en rive gauche doit resté de 492 (effectif marginal) mais peut être réparti différemment dans les modalités de la rive droite.

- L'effectif joint attendu entre espacée en rive gauche et continue en rive droite : $\frac{492 \times 664}{1834} = 178$

## Chi2 - effectif calculé sous $H_0$

[Effectif calculé sous $H_0$]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# run chi2 test
chi2_ripisylve <- chisq.test(table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite))
print(round(chi2_ripisylve$expected[,1:4], 0))
```
Le $\chi^2$ représente la différence des deux tables que l'on compare au $\chi^2$ critique pour déterminer si on peut rejeter $H_0$ avec un une probabilité d'erreur définie (5% généralement). Voir [table de $\chi^2$ par Fabrice Larribe](http://fabricelarribe.uqam.ca/resources/Tables/Table-Chi2-Print.pdf)

## Chi2 - interprétation

```{r, echo=TRUE, collapse=FALSE}
print(chi2_ripisylve)
```
- La p-value représente la probabilité d'obtenir un résultat aussi extrême que celui observé, dans les conditions de $H_0$.

- Cette situation est très improbable. On peut rejeter $H_0$ et valider $H_1$ avec une probabilité de se tromper de $2.2 \times 10^{-16} \times 100$%.

## Qualitatif VS Quantitatif - Discrétisation

Discrétiser une variable quantitative, exemple par seuil de valeurs.

```{r, echo=TRUE, collapse=FALSE}
# create breaks [0,5), [5,10), [10,20), [20,30), [30,40), [40,50), [>50]
largeurs_breaks <- c(0, 5, 10, 20, 30, 40, 50, Inf)
carhyce_stat$largeur_mouillee_qb_m_breaks <- cut(carhyce_stat$largeur_mouillee_qb_m, 
                                                  breaks = largeurs_breaks, 
                                                  include.lowest = TRUE, 
                                                  right = FALSE) # new column with breaks
tab <- table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$largeur_mouillee_qb_m_breaks) # contingency table
addmargins(tab) # with margins (effectifs marginaux)
```

## Description de la distribution par modalité

::: panel-tabset
### Indicateurs

```{r, echo=TRUE, collapse=FALSE}
summary_table <- carhyce_stat %>%
  group_by(continuite_ripisylve_rive_gauche) %>% 
  dplyr::summarize(
    Mean = mean(largeur_mouillee_qb_m, na.rm = TRUE),
    Median = median(largeur_mouillee_qb_m, na.rm = TRUE),
    StdDev = sd(largeur_mouillee_qb_m, na.rm = TRUE)
  )
print(summary_table)
```

### Boxplot

```{r, echo=TRUE, collapse=FALSE, fig.height=3.5}
ggplot(carhyce_stat, aes(x = factor(continuite_ripisylve_rive_gauche), y = largeur_mouillee_qb_m, fill = factor(continuite_ripisylve_rive_gauche))) +
  geom_boxplot() +
  labs(x = "Ripisylve rive gauche", y = "Largeur mouillée (m)", fill = "Ripisylve rive gauche") +
  theme_minimal()
```
:::

## Quantitatif VS quantitatif

La représentation par nuage de point, avec en X plutôt la variable explicative et en Y la variable expliquée.

```{r, echo=TRUE, collapse=FALSE, fig.align='center', fig.height=4}
plot <- ggplot(carhyce_stat, aes(x = debit_plein_bord_m3_s, y = largeur_mouillee_qb_m)) +
  geom_point() +
  labs(x = "Débit de plein bord (m3/s)", y = "Largeur mouillée plein bord (m)") +
  theme_minimal()
plot
```

## Régression ?

::: panel-tabset
### Linéaire

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red")
```


### Polynomiale

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red", formula = y ~ poly(x, 2))
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red", formula = y ~ log(x) + x)
```
:::

## Covariance {.smaller}

**Evalue dans quelle mesure les variations de deux variables sont simultanées ou non.**

- "+" = les écarts entre les valeurs et leur moyenne ont tendance a être de même signe.
- "=" les écarts entre les valeurs et leur moyenne ont tendance a être de signe opposé.
- "0" les écarts entre les $Xi$ et leur moyenne et les écarts entre les $Yi$ et leur moyenne n'ont aucun lien entre eux.

**Attention** : 

- Sa dimension est le produit des dimensions des variables (e.g. euros et années), elle est donc difficile à interpréter.

- Davantage un outil qui permet d'effectuer d'autres calculs comme la corrélation de Person qu'un indicateur utilisé pour l'interprétation (c'est un peu comme la variance et l'écart type).

## Coefficient de corrélation linéaire de Pearson {.smaller}

**Evalue le degré de dépendance linéaire entre deux variables quantitatives. Le résultat dépend de la qualité de l'ajustement affine obtenu par une régression linéaire.**

**Intensité :**

- Proche de 1 (ou -1) = forte dépendance des variables
- Proche de 0 = indépendance des variables

**Sens :**

- ">0" = les variables évoluent dans le même sens
- "<0" = les variables évoluent dans le sens opposé.

Plus on s'éloigne de 0 plus les deux variables sont fortement corrélées linéairement. Le signe indique le sens de la relation.

## Quelques exemples de corrélation

![](./img/pearson_corr_examples.png){width="100%" fig-align="center"}


## Coefficient de détermination

**Le coeffient de corrélation de Pearson au carré. Il détermine le pourcentage de variation de Y imputable à X.**

\

$R^2$% des variations de Y s'expliquent par X.

Par exemple si $R^2 = 0.35$, 35% des variations de la largeur mouillée s'expliquent par le débit.

\

**Attention :** 

- Corrélation $\neq$ causalité!
- Multicolinéarité, quand plusieurs variables explicatives ont des liens de corrélation entre elles!

## Le Quartet d'Anscombe

![](./img/quartet_anscombe.png){width="100%" fig-align="center"}

- Moralité : toujours visualiser les données avant de les analyser ! 🧐

## Coefficient de corrélation de Spearman

- C'est le coefficient de Pearson appliqué aux rangs des variables.

- Similaire au coefficient de Pearson mais ne suppose pas de relation linéaire entre les variables. Il évalue la relation monotone, qui ont tendance à se déplacer dans la même direction relative, entre deux variables indépendamment de la forme.

- L'interprétation est similaire à celle du coefficient de Pearson.

## Calcul des coefficients de corrélation

```{r, echo=TRUE, collapse=FALSE}
# r Pearson correlation
print(paste0("r = ", round(cor.test(carhyce_stat$largeur_mouillee_qb_m, carhyce_stat$debit_plein_bord_m3_s, method = "pearson")$estimate, 2)))
# rho Spearman correlation
print(paste0("rho = ", round(cor.test(carhyce_stat$largeur_mouillee_qb_m, carhyce_stat$debit_plein_bord_m3_s, method = "spearman")$estimate, 2)))
```
Intérêt de calculer les deux coefficients :

- r>$\rho$ : présence éventuelle de valeurs exceptionnelles.
- r<$\rho$ : présence éventuelle d'une relation non linéaire.

## Lire le résultat d'un modèle de régression linéaire {.smaller}

```{r}
model_lineaire <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s, data = carhyce_stat)
summary(model_lineaire)
```
- Résidus : différence entre les valeurs observées et les valeurs prédites par le modèle.
- Erreur standard des résidus : écart-type des résidus (ou la dispersion autour de la droite)
- Coefficients avec erreur standard et test de significativité  :

  - Estimate (Intersept) : b ou l'ordonnée à l'origine
  - Estimate (Variable) : a ou la pente

- R-squared : coefficient de détermination

## Comparaison des modèles régressions

::: panel-tabset

### Linéaire

```{r, echo=TRUE, collapse=FALSE}
model_lineaire <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s, data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_lineaire)[1], 2), " + ", round(coef(model_lineaire)[2], 2), "x"))
# R2
print(paste0("R2 = ", round(summary(model_lineaire)$r.squared, 2)))
# Residual standard error
print(paste0("S = ", round(summary(model_lineaire)$sigma, 2)))
```

### Polynomiale
```{r, echo=TRUE, collapse=FALSE}
# polynomial model (degree 2)
model_poly <- lm(largeur_mouillee_qb_m ~ poly(debit_plein_bord_m3_s, 2), data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_poly)[1], 2), " + ", round(coef(model_poly)[2], 2), "x + ", round(coef(model_poly)[3], 2), "x^2"))
# Residual standard error
print(paste0("S = ", round(summary(model_poly)$sigma, 2)))
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE}
# logarithmic model
model_log <- lm(largeur_mouillee_qb_m ~ log(debit_plein_bord_m3_s), data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_log)[1], 2), " + ", round(coef(model_log)[2], 2), "log(x)"))
# Residual standard error
print(paste0("S = ", round(summary(model_log)$sigma, 2)))
```
:::

## Analyse des résidus {.smaller}

::: panel-tabset

### Linéaire

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_lineaire, which = 1)
```

### Polynomiale

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_poly, which = 1)
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_log, which = 1)
```

:::

- Les résidus doivent être dispersés aléatoirement autour de zéro. La présence d’une tendance (linéaire ou non) indique des effets systématiques ignorés par le modèle.

## Homosédasticité vs Hétérosédasticité

\

![](./img/homosedasticite.png)

## Normalité des résidus {.smaller}

```{r, echo=TRUE, collapse=FALSE, fig.height=3.2}
par(mfrow=c(1,2))
plot(model_lineaire, which = 2)
hist(model_lineaire$residuals, breaks = 100, main = "Histogramme des résidus", xlab = "Résidus")
```
<details>
  <summary>Analyse de la normalité</summary>
- Q-Q plot => détection des déviations systématiques de la normalité des résidus. La distribution des résidus présente une dissymétrie à droite.
- Notre modèle tend à surestimer les valeurs basses et sous-estimer les valeurs hautes.
</details>

::: aside
[Pour aller plus loin : Cours de Philippe Marchand (Université du Québec en Abitibi-Témiscamingue) ](https://pmarchand1.github.io/ECL7102/notes_cours/6-Regression_lineaire.html#suppositions_du_mod%C3%A8le_de_r%C3%A9gression_lin%C3%A9aire)
:::

## Régression linéaire multiple

Plusieurs variables explicatives pour une variable expliquée.

```{r, echo=TRUE, collapse=FALSE, out.height= 1}
# multiple linear regression with two variables
model_multiple <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s + 
                       vitesse_moyenne_qb_m_s + d50_mm + 
                       nombre_transect, data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_multiple)[1], 2), " + ", 
                round(coef(model_multiple)[2], 2), "x1 + ", 
                round(coef(model_multiple)[3], 2), "x2 + ", 
                round(coef(model_multiple)[4], 2), "x3"))
```

## Régression linéaire multiple - interprétation {.smaller}

```{r, echo=TRUE, collapse=FALSE}
summary(model_multiple)
```
<details>
  <summary>Interprétation</summary>
- Le débit, la vitesse, la granulométrie et le nombre de transect expliquent 56% de la variation de la largeur mouillée.
- Les variables explicatives ont toutes un effet légèrement positif sur la largeur mouillée à l'exception de la vitesse qui a un effet fortement négatif.
- Les variables ont un effet significatif sur la largeur mouillée sauf le nombre de transect.
</details>

## Régression linéaire multiple - synthèse

```{r, echo=TRUE, collapse=FALSE}
model_multiple %>%
  tbl_regression(intercept = TRUE)
```

## Régression linéaire multiple - graphique en forêt

```{r, echo=TRUE, collapse=FALSE}
# forest plot
ggstats::ggcoef_model(model_multiple)
```

## Matrice de nuage de points

```{r, echo=TRUE, collapse=FALSE}
pairs(carhyce_stat[, c("vitesse_moyenne_qb_m_s", "debit_plein_bord_m3_s", "largeur_mouillee_qb_m", "d50_mm")])
```

## Corrélations croisées

```{r, echo=TRUE, collapse=FALSE}
pearson <- cor(carhyce_stat[, c("vitesse_moyenne_qb_m_s", "debit_plein_bord_m3_s", "largeur_mouillee_qb_m", "d50_mm")], method = "pearson")
pearson
```

[- Les corrélations linéaire les plus fortes sont entre le débit et la largeur mouillée et entre la vitesse et le débit. Le D50 est peu corrélé avec les autres variables (un peu avec la largeur mouillée). ]{style="font-size: 0.7em;"}

[- Si on prend la largeur mouillée comme variable expliquée, le débit et le D50 semblent être des variables explicatives intéressantes.]{style="font-size: 0.7em;"}

## Corrélations croisées - graphique

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
corrplot(pearson, 
         type = "upper",
         diag = FALSE,
         tl.col = "dark grey",
         tl.srt = 45)
```

# Comparaison de jeux de données

## Hypothèses et problématiques

Hypothèses : 

- Les stations CARHYCE sont représentatives de l'état des rivières françaises pour les petits bassins versants (<100 km2).
- Je peux distinguer les stations de montagne des stations de plaine par leur classification géographique.

Problématiques :

- Les rivières de montagne ont-elles des caractéristiques différentes des rivières de plaine pour les petits bassins versants ?


## Reprenons nos données {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  filter(surface_bv_km2 < 100) %>% # keep surface_bv_km2 data below 100 km2
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         score_ripisylve,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         coefficient_de_sinuosite,
         coefficient_rugosite,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2,
         modele_reference_img,
         montagne_plaine) %>%  # select columns
  na.omit() # remove NA values
```

## Théorème central limite

- Prennons un grand nombre d'échantillons de taille n d'une distribution non normale de moyenne $\mu$ et d'écart-type $\sigma$. Quelle est la distribution des moyennes si on effectue de nombreux tirage aléatoire de taille n?

- Illustration dans le [Grimoire de Lise Vaudor](http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/decrire-une-variable.html#loi-normale){target="_blank"}

- La moyenne d'un grand nombre d'échantillons (n>30) de distribution quelconque de taille n suit une distribution normale, soit $\bar{x} \sim N(\mu, \frac{\sigma}{\sqrt{n}})$

::: aside

$\mu$ = moyenne de la population, $\sigma$ = écart-type de la population, $n$ = taille de l'échantillon

:::

## Erreur standard {.smaller}

- L'écart type est un indicateur de la dispersion des valeurs d'un échantillon (ou d'une population) autour de la moyenne.

- L'erreur standard est l'écart type d'un paramètre (moyenne, pourcentage, etc.). Notre moyenne de notre jeu de données (ou échantillon) n'est qu'une estimation de la moyenne de la population. Si on refaisait l'échantillonnage, on obtiendrait une autre moyenne à cause des fluctuations d'échantillonnage. L'erreur standard est l'écart type de ces moyennes.

- L'erreur standard de la moyenne d'un échantillon peut être calculé : $\frac{\sigma}{\sqrt{n}}$. Il a donc la particularité de diminuer avec la racine carrée de la taille de l'échantillon, contrairement à l'écart type d'un échantillon.

::: aside

Une explication complète et très pédagogique est dans l'annexe 3 des [Statistiques pour statophobes (2004) de Denis Poinsot](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf).

:::

## Intervalle de confiance de la moyenne (n>30, distribution quelconque) {.smaller}

- Selon le théorème central limite, la moyenne calculé sur un grand échantillon $m$ suit une loi approximativement normale de moyenne $\mu$ (de la population) $\mu$ et d'écart type (ou erreur standard) $\frac{\sigma}{\sqrt{n}}$.

- Nous avons un grand échantillon, l'écart-type de l'échantillon est donc une bonne estimation de l'écart-type de la population. 

- Dans une distribution normale, 95% des valeurs se trouvent dans l'intervalle $IC_{95\%} = [\bar x-1.96\frac{s}{\sqrt{n}},\bar x+1.96\frac{s}{\sqrt{n}}]$. On peut donc dire que la moyenne de l'échantillon a 95% de chance de se trouver dans cet intervalle. On peut remplacer 1.96 par n'importe quelle valeur critique de la loi normale pour son niveau de confiance associé (pour un niveau de confiance de 99%, la valeur critique est de 2.575).

::: aside

$\mu$ = moyenne de la population, $\bar x$ = moyenne de l'échantillon, $\sigma$ = écart-type de la population, $s$ = écart-type de l'échantillon, $n$ = taille de l'échantillon

:::

## Intervalle de confiance de la moyenne (n<30, distribution normale) {.smaller}

- La distribution est normale mais on ne peut plus remplacer l'écart-type de la population $\sigma$ par l'écart-type de l'échantillon $s$. L'écart-type de la population est alors remplacé par le $t$ de Student pour $n-1$ degrés de liberté (df ou degrees of freedom en anglais). 

- Les degrées de liberté sont le nombre de valeurs susceptible de varier dans un calcul statistique. Les observations d'un échantillon peuvent variées d'un échantillon à l'autre, reflétant la variabilité inhérente des données dans la population. Les degrés de liberté sont un concept statistique qui quantifie combien de valeurs peuvent encore varier après que certaines restrictions ont été appliquées. Dans le cas de l'échantillon, si vous connaissez la moyenne $\bar x$, toutes les valeurs de l'échantillon doivent s'ajuster pour que la somme totale des écarts à la moyenne soit nulle. Cela signifie que si n est la taille de l'échantillon, seulement n-1 valeurs peuvent varier indépendamment, la dernière est déterminée par les autres.

- L'intervalle de confiance est alors pour $IC_{95\%} = [\bar x-t_{0.975}\frac{s}{\sqrt{n}},\bar x+t_{0.975}\frac{s}{\sqrt{n}}]$. On peut remplacer $t_{0.975}$ par n'importe quelle valeur critique de la loi de Student pour son niveau de confiance associé.

## Intervalle de confiance de la moyenne (n>30 ou distribution normale) - calcul

```{r, echo=TRUE, collapse=FALSE}
# mean confidence interval for the sample with 95% confidence level
t.test(carhyce_stat$largeur_mouillee_qb_m, conf.level = 0.95)
```

## Intervalle de confiance de la moyenne (n<30, distribution non normale) {.smaller}

- La méthode du bootstrap : on simule d'une manière itérative et inductive une multitude d'échantillons analogues à l'échantillon initial. On calcule la moyenne de chaque échantillon et on obtient la distribution des moyennes. L'intervalle de confiance est alors déterminé par les quantiles de cette distribution.

```{r, echo=TRUE, collapse=FALSE}
# sample 20 values from the population
sample_largeur <- sample(carhyce_stat$largeur_mouillee_qb_m, 20)
print(paste0("Moyenne du sous échantillon = ", median(sample_largeur)))
```
```{r, echo=TRUE, collapse=FALSE}
bootstat <- function(x, i) median(x[i]) # bootstrap function
# mean confidence interval for the sample with 95% confidence level
mean_ci_sample <- boot(data = sample_largeur, statistic = bootstat, R = 1000)
boot.ci(mean_ci_sample, type = "basic", conf = 0.95)
```
## Intervalle de confiance d'une médiane

- La méthode du bootstrap peut être utilisée.

```{r, echo=TRUE, collapse=FALSE}
print(paste0("Médiane = ", median(carhyce_stat$largeur_mouillee_qb_m)))
bootstat <- function(x, i) median(x[i]) # bootstrap function
# mean confidence interval for the sample with 95% confidence level
median_ci_sample <- boot(data = carhyce_stat$largeur_mouillee_qb_m, statistic = bootstat, R = 1000)
boot.ci(median_ci_sample, type = "basic", conf = 0.95)
```

```{r, echo=FALSE, include=FALSE}
# Median confidence interval for symmetric distribution 
wilcox.test(carhyce_stat$largeur_mouillee_qb_m, conf.int = TRUE)
```

## Comparaison des stations de plaine et de montagne

**Est-ce que les rivières de montagne ont une granulométrie plus grossière que les rivières de plaine?**

\

Séparation des jeux de données.

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_montagne <- carhyce_stat %>% filter(montagne_plaine == "montagne")
carhyce_stat_montagne_mean = mean(carhyce_stat_montagne$d50_mm, na.rm = TRUE)
print(paste0("Moyenne D50 station de montage = ", round(carhyce_stat_montagne_mean, 2)))
```

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_plaine <- carhyce_stat %>% filter(montagne_plaine == "plaine")
carhyce_stat_plaine_mean = mean(carhyce_stat_plaine$d50_mm, na.rm = TRUE)
print(paste0("Moyenne D50 station de montage = ", round(carhyce_stat_plaine_mean, 2)))
```
## Vérification des distributions

```{r}
# histogram with normal curve
par(mfrow=c(1,2))
h <- hist(carhyce_stat_montagne$d50_mm, col = "lightblue", main = "Montagne", 
          xlab = "D50 (mm)", ylim = c(0, 20))
xfit <- seq(min(carhyce_stat_montagne$d50_mm),
            max(carhyce_stat_montagne$d50_mm), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$d50_mm), sd = sd(carhyce_stat_montagne$d50_mm)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$d50_mm) 
lines(xfit, yfit, col = "red", lwd = 2)
h <- hist(carhyce_stat_plaine$d50_mm, col = "lightgreen", main = "Plaine", 
          xlab = "D50 (mm)")
xfit <- seq(min(carhyce_stat_plaine$d50_mm),
            max(carhyce_stat_plaine$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine$d50_mm), sd = sd(carhyce_stat_plaine$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
```

## Conditions de comparaison des moyennes

![](./img/t-test-diagram.png){width="100%" fig-align="center"}

<!-- ## Conditions de comparaison des moyennes -->

[Si la distribution est très dissymétrique malgrés un échantillon >30 => test non paramétrique.]{style="font-size: 0.7em;"}


## Comparaison de moyennes - IC95%

```{r, echo=TRUE, collapse=FALSE}
print(paste0("Taille de l'échantillon montagne : ", nrow(carhyce_stat_montagne)))
print(paste0("Taille de l'échantillon plaine : ", nrow(carhyce_stat_plaine)))
```
\

[Condition n>30, distribution quelconque]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# mean confidence interval with 95% confidence level
montagne_t_test <- t.test(carhyce_stat_montagne$d50_mm, conf.level = 0.95)
print(paste0("Montagne mean ", round(carhyce_stat_montagne_mean, 2), " IC95% = ", "[", round(montagne_t_test$conf.int[1], 2), " - ", round(montagne_t_test$conf.int[2], 2), "]"))
plaine_t_test <- t.test(carhyce_stat_plaine$d50_mm, conf.level = 0.95)
print(paste0("Plaine mean ", round(carhyce_stat_plaine_mean, 2), " IC95% = ", "[", round(plaine_t_test$conf.int[1], 2), " - ", round(plaine_t_test$conf.int[2], 2), "]"))
```
## Comparaison de moyennes - IC boxplot

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# boxplot with mean, confidence interval and their values
boxplot(carhyce_stat$d50_mm ~ carhyce_stat$montagne_plaine, main = "Granulométrie d50", xlab = "", ylab = "Granulométrie d50 (mm)", col = c("lightblue", "lightgreen"))
points(1, carhyce_stat_montagne_mean, pch = 19, col = "red")
segments(1, montagne_t_test$conf.int[1], 1, montagne_t_test$conf.int[2], col = "red")
points(2, carhyce_stat_plaine_mean, pch = 19, col = "red")
segments(2, plaine_t_test$conf.int[1], 2, plaine_t_test$conf.int[2], col = "red")
text(1, montagne_t_test$conf.int[2], paste0(round(carhyce_stat_montagne_mean, 2), " [", round(montagne_t_test$conf.int[1], 2), " - ", round(montagne_t_test$conf.int[2], 2), "]"), pos = 3) # 
text(2, plaine_t_test$conf.int[2], paste0(round(carhyce_stat_plaine_mean, 2), " [", round(plaine_t_test$conf.int[1], 2), " - ", round(plaine_t_test$conf.int[2], 2), "]"), pos = 3) # add values of means and confidence intervals
abline(h = 35, col = "red") # add horizontal line at 35 mm
```
## Test de comparaison des variances

F-test pour comparer les variances :

$H_0$ : les variances sont égales
$H_1$ : les variances ne sont pas égales

```{r, echo=TRUE, collapse=FALSE}
# F-test
var.test(carhyce_stat_montagne$d50_mm, carhyce_stat_plaine$d50_mm)
```
La p-value est inférieure à 0.05, l'hypothèse nulle est rejetée, les variances des granulométries des rivières de montagne et de plaine sont significativement différentes.

## Test de comparaison des moyennes - Welch t-test {.smaller}

- Test de Welch pour comparer les moyennes de deux échantillons indépendants de variance égales. (le t.test de R réalise un test de variance automatique et réalise automatiquement un test de Welch si les variances sont égales).

- Hypothèses :

    - $H_0$ : les moyennes des deux échantillons sont égales.
    - $H_1$ : les moyennes des deux échantillons sont différentes.
    
```{r, echo=TRUE, collapse=FALSE}
# Welch test
t.test(carhyce_stat_montagne$d50_mm, carhyce_stat_plaine$d50_mm,
       var.equal = FALSE, # Welch test
       alternative = "two.sided", # test difference of means
       paired = FALSE) # independant samples
```
https://www.datanovia.com/en/fr/lessons/test-t-dans-r/


L'hypothèse nulle est rejetée, les moyennes des granulométries des rivières de montagne et de plaine sont significativement différentes avec un risque de se tromper de 0.52%.

## Petits échantillons ou distributions non normales

```{r, echo=TRUE, collapse=FALSE}
# montagne data with only PYRENEES
carhyce_stat_montagne_vosges <- carhyce_stat %>% filter(modele_reference_img == "VOSGES")
# dataset dimension and mean
print(paste0("row number : ", dim(carhyce_stat_montagne_vosges)[1]))
print(paste0("mean : ", mean(carhyce_stat_montagne_vosges$d50_mm, na.rm = TRUE)))
```

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_plaine_collineen <- carhyce_stat %>% filter(modele_reference_img == "Plaine/collinéen calcaire")
# dataset dimension and mean
print(paste0("row number : ", dim(carhyce_stat_plaine_collineen)[1]))
print(paste0("mean : ", mean(carhyce_stat_plaine_collineen$d50_mm, na.rm = TRUE)))
```

## Les distributions sont-elles normales? - Code

```{r, echo=FALSE, eval=FALSE, collapse=FALSE, fig.width=15}
par(mfrow=c(1,2))
# Histogram with normal curve - Montagne
h <- hist(carhyce_stat_montagne$largeur_mouillee_qb_m, col = "lightblue", main = "Largeur mouillée plein bord - la montagne", xlab = "Largeur mouillée plein bord (m)", ylim = c(0, 40), breaks = 30) 
xfit <- seq(min(carhyce_stat_montagne$largeur_mouillee_qb_m),
            max(carhyce_stat_montagne$largeur_mouillee_qb_m), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$largeur_mouillee_qb_m), sd = sd(carhyce_stat_montagne$largeur_mouillee_qb_m)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$largeur_mouillee_qb_m) 
lines(xfit, yfit, col = "red", lwd = 2)

# Histogram with normal curve - Plaine
h <- hist(carhyce_stat_plaine$largeur_mouillee_qb_m, col = "lightblue", main = "Largeur mouillée plein bord - la montagne", xlab = "Largeur mouillée plein bord (m)", breaks = 30) 
xfit <- seq(min(carhyce_stat_plaine$largeur_mouillee_qb_m),
            max(carhyce_stat_plaine$largeur_mouillee_qb_m), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine$largeur_mouillee_qb_m), sd = sd(carhyce_stat_plaine$largeur_mouillee_qb_m)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine$largeur_mouillee_qb_m) 
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, eval=FALSE, collapse=FALSE}
# Shapiro-Wilk test - Montagne
shapiro.test(carhyce_stat_montagne$largeur_mouillee_qb_m)
# Shapiro-Wilk test - Plaine
shapiro.test(carhyce_stat_plaine$largeur_mouillee_qb_m)
```




## Les distributions sont-elles normales?

```{r, echo=FALSE, collapse=FALSE, fig.width=15}
par(mfrow=c(1,2))
# Histogram with normal curve - Montagne
h <- hist(carhyce_stat_montagne$largeur_mouillee_qb_m, col = "lightblue", main = "Largeur mouillée plein bord - la montagne", xlab = "Largeur mouillée plein bord (m)", ylim = c(0, 40)) 
xfit <- seq(min(carhyce_stat_montagne$largeur_mouillee_qb_m),
            max(carhyce_stat_montagne$largeur_mouillee_qb_m), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$largeur_mouillee_qb_m), sd = sd(carhyce_stat_montagne$largeur_mouillee_qb_m)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$largeur_mouillee_qb_m) 
lines(xfit, yfit, col = "red", lwd = 2)

# Histogram with normal curve - Plaine
h <- hist(carhyce_stat_plaine$largeur_mouillee_qb_m, col = "lightblue", main = "Largeur mouillée plein bord - la montagne", xlab = "Largeur mouillée plein bord (m)") 
xfit <- seq(min(carhyce_stat_plaine$largeur_mouillee_qb_m),
            max(carhyce_stat_plaine$largeur_mouillee_qb_m), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine$largeur_mouillee_qb_m), sd = sd(carhyce_stat_plaine$largeur_mouillee_qb_m)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine$largeur_mouillee_qb_m) 
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, collapse=FALSE}
# Shapiro-Wilk test - Montagne
shapiro.test(carhyce_stat_montagne$largeur_mouillee_qb_m)
# Shapiro-Wilk test - Plaine
shapiro.test(carhyce_stat_plaine$largeur_mouillee_qb_m)
```
## Mes variances sont-elles égales?

F-test pour comparer les variances

$H_0$ : les variances sont égales
$H_1$ : les variances sont différentes

Seuil de significativité : 0.05

```{r}
# F-test
var.test(carhyce_stat_montagne$largeur_mouillee_qb_m, carhyce_stat_plaine$largeur_mouillee_qb_m)
```
```{r}
var.equal=FALSE # by default
if(var.test(carhyce_stat_montagne$largeur_mouillee_qb_m, carhyce_stat_plaine$largeur_mouillee_qb_m)$p.value>=0.05){
  var.equal=TRUE
}
var.equal
```



```{r, echo=TRUE, collapse=FALSE}
# T-test
t.test(carhyce_stat_montagne$largeur_mouillee_qb_m, carhyce_stat_plaine$largeur_mouillee_qb_m)
```

## histogramme


```{r}
# Histogram with normal curve
h <- hist(carhyce_stat$rayon_hydraulique_qb, col = "lightblue", main = "Rayon hydraulique plein bord", xlab = "Rayon hydraulique plein bord (m)") 
xfit <- seq(min(carhyce_stat$rayon_hydraulique_qb),
            max(carhyce_stat$rayon_hydraulique_qb), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat$rayon_hydraulique_qb), sd = sd(carhyce_stat$rayon_hydraulique_qb)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat$rayon_hydraulique_qb) 
lines(xfit, yfit, col = "red", lwd = 2)
```

## Test de normalité

```{r}
# Shapiro-Wilk test
shapiro.test(carhyce_stat$rayon_hydraulique_qb)

```



```{r}
# Histogram with normal curve
h <- hist(carhyce_stat_montagne$rayon_hydraulique_qb, col = "lightblue", main = "Débit de plein bord", xlab = "Débit de plein bord (m3/s)") 
xfit <- seq(min(carhyce_stat_montagne$rayon_hydraulique_qb),
            max(carhyce_stat_montagne$rayon_hydraulique_qb), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$rayon_hydraulique_qb), sd = sd(carhyce_stat_montagne$rayon_hydraulique_qb)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$rayon_hydraulique_qb) 
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r}
# Shapiro-Wilk test
shapiro.test(carhyce_stat_montagne$rayon_hydraulique_qb)
```



# Analyse multivariée / multidimensionnelle

## Analyse multivariée / multidimensionnelle {.smaller}

- L'objectif est de synthétiser et de structurer l'information contenue dans des données multidimensionnelles (I individus, K variables) => méthode d'exploration des données.

| Analyse    | Variables                                        | Fonction standard      | Fonction ade4          | Fonctions FactoMineR    |
|----------------|--------------------------------------------------|------------------------|------------------------|-------------------------|
| ACP            | plusieurs variables quantitatives                | stats::princomp()      | ade4::dudi.pca()       | FactoMineR::PCA()       |
| AFC            | deux variables qualitatives                      | MASS::corresp()        | ade4::dudi.coa()       | FactoMineR::CA()        |
| ACM            | plusieurs variables qualitatives                 | MASS::mca()            | ade4::dudi.acm()       | FactoMineR::MCA()       |
| Analyse mixte  | plusieurs variables quantitatives et/ou qualitatives | —                      | ade4::dudi.mix()       | FactoMineR::FAMD()      |

::: aside
Source tableau : [Joseph Larmarange 2024](https://larmarange.github.io/guide-R/analyses_avancees/analyse-factorielle.html)
:::

## Etude des individus et des variables

- Analyse de la variabilité entre les individus : 
  - Quels sont leurs caractéristiques communes ?
  - Peut-on identifier des profils d'individus ?

- Analyse des variables :
  - Quels sont les liaisons entre les variables ?
  - Peut-on identifier des groupes de variables ?
  
- exemples : 30 individus et 4 variables : 
  - les variables ont 30 dimensions dans l'espace des individus.
  - les individus ont 4 dimensions dans l'espace des variables.

## Centrage et réduction

- Les variables sont sonvent exprimées dans des unités différentes, les effets d'échelles les rendent difficile à comparer.

- On les centre : on soustrait la moyenne de chaque variable à chaque observation.

- On les réduit : on divise par l'écart-type de chaque variable.

- On obtient des variables centrées-réduites, qui ont une moyenne nulle et une variance égale à 1.

## Reprenons nos données {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         score_ripisylve,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         coefficient_de_sinuosite,
         coefficient_rugosite,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2,
         montagne_plaine) # select columns
```

## Analyse en composantes principales (ACP)

**ACP sur tous les individus et toutes les variables :**

```{r, echo=TRUE, collapse=FALSE}
# PCA
pca <- PCA(carhyce_stat[, c("score_ripisylve", "profondeur_moyenne_qb_m", "largeur_mouillee_qb_m", "surface_mouillee_qb_m2", "rayon_hydraulique_qb", "d16_mm", "d50_mm", "d84_mm", "coefficient_de_sinuosite", "coefficient_rugosite", "debit_plein_bord_m3_s", "vitesse_moyenne_qb_m_s", "cote_ligne_energie_qb", "nombre_de_froude_qb", "force_tractrice_qb_n_m2")], 
            ncp = Inf, # number of dimensions
            scale.unit = TRUE, # reduce
            graph = FALSE) # not display graph
print(pca)
```

## ACP - Vocabulaire et information

- **eig** : eigenvalues (valeurs propres)
- **ind** : individus
- **var** : variables
- **coord** : coordonnées dans l'espace des individus ou des variables
- **cos2** : qualité de représentation d'un individu ou d'une variable
- **contrib** : contribution d'un individu ou d'une variable au calcul de l'axe


## ACP - Analyse des valeurs propres

- Quantité de variance expliquée par chaque axe (ou inertie).

```{r, echo=TRUE, collapse=FALSE}
pca$eig
```
- Les trois premiers axes permettent d'expliquer 61% de la variance.

## ACP - Analyse graphique des valeurs propres

[Peut-on résumer l'essentiel de l'information avec un nombre réduit de dimensions (ou axes) ? => On cherche un "coude", un point d'inflexion.]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# Scree plot
fviz_eig(pca, addlabels = TRUE)
```
[On trouve 2 points d'inflexion. Le premier axe est particulièrement intéressant avec 30% de l'inertie.]{style="font-size: 0.7em;"}

## ACP - Critère de Kaiser

[On ne garde que les axes dont la valeur propre est supérieure à 1 (1 = inertie moyenne si les variables sont centrées et réduites).]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
barplot(pca$eig[,1],xlab = "facteur", ylab = " Inertie (eigenvalue) ", col="blue")
```

## ACP - Contribution au premier axe

[Quelles sont les variables qui contribuent le plus à l'inertie du premier axe ? Ou quelles sont les contributions des modalités de l'axe ?]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
fviz_contrib(pca, choice = "var", axes = 1)
```

[Le premier axe se composent principalement de variables de géométrie avec le débit]{style="font-size: 0.7em;"}

## ACP - Contribution au deuxième axe

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
fviz_contrib(pca, choice = "var", axes = 2)
```

## ACP - Interprétation graphique

![](./img/pca.png){style="width: 100%"}

::: aside
Voir [le blog de Lise Vaudor, CNRS, 2021](http://perso.ens-lyon.fr/lise.vaudor/acp/)
:::

## ACP - Modalités dans le plan factoriel

[Le cercle des corrélations :]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
fviz_pca_var(pca, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
```
## ACP - Les individus dans le plan factoriel

[Répartition des individus dans les deux premiers axes.]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
fviz_pca_ind(pca, geom.ind = "point",
             alpha.ind = 0.3) # densité de points superposées
```

## ACP Explor

Des variables et/ou individus supplémentaires, non pris en compte dans les calculs, peuvent être ajoutés pour l'interprétation.

```{r, echo=TRUE, collapse=FALSE}
pca <- PCA(carhyce_stat, 
           quanti.sup = 1,
           quali.sup = c(2,3,4,19),
           ncp = Inf, # number of dimensions
           scale.unit = TRUE, # reduce
           graph = FALSE) # not display graph
```
Visualisation avec explor : 
```{r, echo=TRUE, collapse=FALSE}
# package explor
explor(pca)
```

```{r, echo=TRUE, collapse=FALSE, results='hide'}
res <- explor::prepare_results(pca)
explor::PCA_ind_plot(res, xax = 1, yax = 2, ind_sup = FALSE, lab_var = NULL,
    ind_lab_min_contrib = 0, col_var = "montagne_plaine", labels_size = 9, point_opacity = 0.5,
    opacity_var = NULL, point_size = 28, ellipses = TRUE, transitions = TRUE,
    labels_positions = NULL, xlim = c(-6.59, 8.54), ylim = c(-7.28, 7.86))
```


## ACP Explor - Graphique

```{r, echo=FALSE, collapse=FALSE, fig.align='center', fig.height=8}
res <- explor::prepare_results(pca)
explor::PCA_ind_plot(res, xax = 1, yax = 2, ind_sup = FALSE, lab_var = NULL,
    ind_lab_min_contrib = 0, col_var = "montagne_plaine", labels_size = 9, point_opacity = 0.5,
    opacity_var = NULL, point_size = 28, ellipses = TRUE, transitions = TRUE,
    labels_positions = NULL, xlim = c(-6.59, 8.54), ylim = c(-7.28, 7.86))
```

# Classification

## Classification supervisée vs non supervisée {.smaller}

- **Supervisée** : on connait les classes à l'avance, on cherche à prédire la classe d'un nouvel individu à partir de différentes variables.
  - Exemple : on a une image satellite et on cherche à identifier les zones urbaines sur la base des valeurs des pixels. On identifie des zones urbains et non urbaines pour entrainer le modèle. On se sert du modèle pour prédire les zones urbaines sur une nouvelle image.
  - Méthodes : régression logistique, SVM, Random Forest
- **Non supervisée** : on ne connait pas les classes à l'avance, on cherche à regrouper les individus en fonction de leurs ressemblances.
  - Exemple : à partir d'un image satellite, on cherche à regrouper les pixels en fonction de leurs valeurs et identifier des zones homogènes que l'on suppose correspondre à des occupations du sol différentes.
  - Méthodes : K-means, CAH

## Classification ascendante hiérarchique (CAH) {.smaller}

- Une méthode non supervisée qui permet de regrouper des individus en fonction de leurs ressemblances.
- On cherche à ce que les individus regroupés au sein d’une même classe (homogénéité intra-classe) soient le plus semblables possibles tandis que les classes soient le plus dissemblables (hétérogénéité inter-classe).
- La ressemblance ou la dissemblance entre les individus est mesurée à l'aide d'une matrice distances entre chaque individus pris deux à deux. Plus la distance est faible, plus les individus sont semblables.
- La CAH part des individus (ascendante) et les regroupe progressivement en classes de plus en plus grandes (hiérarchique) => dendrogramme.

::: aside
Voir [le guide de Joseph Larmarange IRD, 2024](https://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.html) ou [Analyse-R](https://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.html)
:::

## Reprenons nos données {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2) %>%  # select columns
  na.omit() # remove NA
```

## Normalisation des données {.smaller}

- Toujours avoir une étape de description des données (distribution, qualité, graph de corrélation, etc.).

- Homogénéisation des données pour éviter les effets d'échelle (unités différentes) et que les variables à forte variance soit prépondérante dans les résultats.

Transformation de Milligan & Cooper
```{r, echo=TRUE, collapse=FALSE}
# Milligan & Cooper transformation function
normalize_MC <- function(x) {
                               return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
                            }
# normalize data
carhyce_stat_mc<-as.data.frame(lapply(carhyce_stat, normalize_MC))
```

\

Transformation z-score (centrage-réduction)
```{r, echo=TRUE, collapse=FALSE}
# z-score transformation
carhyce_stat_z <- scale(carhyce_stat, center = TRUE, scale = TRUE)
```

## La matrice de distance

- Plusieurs méthode de calcul de distance : 
  - **Variables quantitative** : euclidienne, manhattan, Gower, etc.
  - **Variables qualitative** : Gower, $\phi^2$, etc.

```{r, echo=TRUE, collapse=FALSE}
# Euclidean distance
dist_euclid <- dist(carhyce_stat_mc, method = "euclidean")
```

## Agrrégation et dendrogramme
  
```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# Ward method
hc <- hclust(dist_euclid, method = "ward.D2")
# Dendrogram
plot(hc, hang = -1, cex = 0.6, main = "Dendrogramme CAH")
```
## Nombre de classes

- Evaluation graphique sur le dendrogramme.
- Représentation des pertes d'inertie inter-classe (mesure la séparation entre chaque classe). Plus le saut est grand plus la distance entre les clusters fusionnés est grande.

## Nombre de classes - Inertie

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
v <- sort(hc$height,decreasing=T)
plot(1:length(v),v,type = "s", xlab = "Nombre de classes", ylab = "Inertie", xlim = c(0, 30),
     xaxt = "n")
axis(1, at = seq(1, 30, by = 1), las=2)
```

## Découper les classes

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
plot(hc, labels = FALSE, main = "Partition en 2, 5 ou 8 classes", xlab = "", ylab = "", sub = "", axes = FALSE, hang = -1)
rect.hclust(hc, 2, border = "green3")
rect.hclust(hc, 5, border = "red3")
rect.hclust(hc, 8, border = "blue3")
```

```{r, echo=TRUE, collapse=FALSE}
# cut dendrograme in 5 classes
hc_gp <- cutree(hc,k=5)
```

## Interprétation CAH

- Quelles sont les distributions des variables dans chaque classe ?
- Quelles sont les caractéristiques des individus dans chaque classe ?
- Quelles sont les caractéristiques des classes ?

```{r, echo=TRUE, collapse=FALSE, fig.align='center', eval=FALSE}
# box plot each class for each variable
carhyce_stat$group <- as.factor(hc_gp)
carhyce_stat %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = group, y = value, fill = group)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Interprétation CAH - boxplot variables

```{r, echo=FALSE, collapse=FALSE, fig.align='center'}
# box plot each class for each variable
carhyce_stat$group <- as.factor(hc_gp)
carhyce_stat %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = group, y = value, fill = group)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Interprétation CAH - boxplot classes

```{r, echo=TRUE, collapse=FALSE, fig.align='center', fig.width=15}
# variables boxplots for class 2 only
carhyce_stat %>%
  filter(group == 2) %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() + theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Interprétation CAH - ACP

```{r, echo=TRUE, collapse=FALSE}
# PCA
pca <- PCA(carhyce_stat, ncp = Inf, scale.unit = TRUE, graph = FALSE,
            quali.sup = 14) # illustrative group variable
# explor(pca)
```

```{r, echo=FALSE, collapse=FALSE, fig.align='center', fig.height=7}
res <- explor::prepare_results(pca)
explor::PCA_ind_plot(res, xax = 1, yax = 2, ind_sup = FALSE, lab_var = NULL,
    ind_lab_min_contrib = 0, col_var = "group", labels_size = 9, point_opacity = 0.5,
    opacity_var = NULL, point_size = 64, ellipses = TRUE, transitions = TRUE,
    labels_positions = NULL, xlim = c(-6.76, 11.9), ylim = c(-8.72, 9.95))
```

## Classification K





