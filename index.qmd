---
title: "Statistiques et data mining"
subtitle: "Master Hydrosyst√®mes et Bassins Versants"
author: "Louis Mani√®re"
institute: "Universit√© de Tours"
date: last-modified
license: "code : MIT License, presentation : CC BY-NC"
lang: "fr"
format: 
  revealjs:
    navigation-mode: vertical
    theme: custom.scss
    logo: "./img/universite-tours-logo.png"
    footer: "Master 1 Hydrosyst√®mes et Bassins Versants 2024-2025"
    css: custom.css
    slide-number: true
    show-slide-number: all
    smaller: false
    chalkboard: true
    margin: 0.2
    width: 1150
    df-print: kable
editor: visual
---

# Introduction

## Les statistiques

L'ensemble des m√©thodes qui ont pour objet la collecte, le traitement et l'interpr√©tation de donn√©es d'observation relatives √† un groupe d'individus ou d'unit√©s.

- Statistique descriptive : D√©crire, r√©sumer, visualiser des donn√©es.
- Statistique inf√©rentielle (Inf√©rence statistique) : induire des caract√©ristiques sur une population √† partir d'un √©chantillon (relation, distribution).

## Population ou √©chantillon ?

- **Population** : ensemble des individus ou unit√©s statistiques sur lesquels on veut faire des observations.
- **Echantillon** : sous-ensemble de la population, choisi de mani√®re al√©atoire ou non, qui permet de faire des observations.

S√©lection de tous les bruns de la salle, population ou √©chantillon ?

![](./img/population_echantillon.webp){fig-align="center"}

## Le data mining

L'exploration et l'analyse de base de donn√©es pour le r√©sumer, d√©tecter des r√®gles, des tendances, des associations ou des structures particuli√®res. L'exploration des bases de donn√©es existantes en g√©osciences peut √™tre utilis√©e pour d√©tecter des nouvelles tendances ou comportements dans des milieux ou bien pr√©parer une √©tude avant de une campagne de mesure.

## Objectifs du cours {.smaller}

- Apprendre √† d√©crire un jeu de donn√©es, le synth√©tiser pour mettre en √©vidence les informations pertinentes qu'il contient et ses limites pour r√©pondre √† certaines questions.

- Pourvoir cr√©er de nouvelles informations √† partir de relations ou comportements identifi√©s dans les donn√©es. Utiliser ces informations pour pr√©dire de nouvelles donn√©es et identifier communaut√© d'individus communs ou diff√©rents.

- Acqu√©rir des outils de manipulation, description et d'analyse de donn√©es.

- Avoir une d√©marche critique sur les donn√©es, les outils statistiques et les r√©sultats obtenus.

## R et RStudio

::: columns
::: {.column width="50%"}

- Un logiciel et language de d√©veloppement tr√®s complet, gratuit et open source avec une communaut√© active. 
- Permet de reproduire et partager facilement les analyses. 
- Un d√©but apprentissage un peu plus difficile que des logiciels "cl√© en main".
:::

::: {.column width="50%"}
![](./img/Rscary.webp){width="100%"} [^1]
:::
:::

[^1]: Artwork by @allison_horst.

## Ressources et sources du cours {.smaller}

- [Les statistiques pour statophobes (2004), Denis Poinsot](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf){target="_blank"}
- Data Mining et Statistique d√©cisionnelle (2017), St√©phane Tuff√©ry, Editions Technip
- [Analyse-R, Joseph Larmarange - Universit√© Paris Cit√©, IRD](https://larmarange.github.io/analyse-R/){target="_blank"}
- [Guide-R, Joseph Larmarange - Universit√© Paris Cit√©, IRD](https://larmarange.github.io/guide-R/){target="_blank"}
- [Grimoire, Lise Vaudor, CNRS](http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/intro.html){target="_blank"}
- [Cours d'Eric Marcon, Agro Paris Tech](https://ericmarcon.github.io/Cours-R-Geeft/){target="_blank"}
- [Cours d'Antoine Mass√©, IUT de Bordeaux](https://sites.google.com/site/rgraphiques/home){target="_blank"}
- [R for datascience, Hadley Wickham, Mine √áetinkaya-Rundel, and Garrett Grolemund](https://r4ds.hadley.nz/){target="_blank"}
- [Formation minist√©rielle √† R et aux sciences des donn√©es](https://mtes-mct.github.io/parcours-r/){target="_blank"}
- [Vid√©os d'Eric Lombardot - Universit√© Paris 1 Panth√©on Sorbonne](https://www.youtube.com/@EricLombardot){target="_blank"}
- [Vid√©os de Tierry Ancelle, EHESP, MCU-PH, Facult√© de m√©decine Paris-Descartes](https://www.epiter.org/page/2366997-lecons-epiteriennes-en-ligne){target="_blank"}

Pour √©viter R studio : 
- [Logiciel Jamovi](https://www.jamovi.org/){target="_blank"}
- [Logiciel Rattle](https://github.com/gjwgit/rattleng){target="_blank"}
  
## Plan du cours

- Introduction
- Statistiques univari√©es
- Statistiques bivari√©es
- La comparaison de jeux de donn√©es
- Statistiques multivari√©es ou  multimentionnelles
- Classification

## Donn√©es utilis√©es

- Donn√©es hydromorphologiques issus du protocole CARHYCE (Agence Fran√ßaise de la Biodiversit√©), disponible sur [IED CARHYCE](https://analytics.huma-num.fr/ied_carhyce/){target="_blank"}
  - Mesure de morphologie du lit, de granulom√©trie, de d√©bit et de ripisylve.
  - Des donn√©es enrichies par des estimations √† plein bord et les surfaces des bassins versant.
  - Plus de 2000 stations de mesures.

## Installation des (nombreux?) packages

```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
# install all necessary packages
install.packages(c("ggplot2", "dplyr", "tidyr", "tibble", 
                   "janitor", "skimr", "dataMaid", "plotly", 
                   "e1071", "gmodels", "ggpmisc", "nortest", 
                   "FactoMineR", "factoextra", "gtsummary", 
                   "explor", "boot", "qqplotr", "corrplot"))
```


## Importons les pakages du cours

```{r, echo=TRUE, collapse=FALSE, results='hide'}
library(ggplot2) # Graphics
library(dplyr) # Data manipulation
library(tidyr) # Data cleaning
library(tibble) # Table visualisation
library(janitor) # Column names cleaning
library(skimr) # Data summary
library(dataMaid) # Data report
library(plotly) # Interactive plots
library(e1071) # Skewness
library(gmodels) # Contingency tables
library(ggpmisc) # Regression line
library(nortest) # Normality tests
library(FactoMineR) # Factorial analysis
library(factoextra) # Factorial analysis
library(gtsummary) # Regression summary
library(explor) # Data exploration
library(boot) # Bootstrap
library(qqplotr) # QQ-plot
library(corrplot) # Correlation plot
```

## Explorons le jeu de donn√©es

```{r, echo=TRUE, collapse=FALSE, results='hide'}
# import dataset
carhyce_brute <- read.csv("data/Operations_CARHYCE_2024-06-25.csv",
                  sep=";",dec=",",header=TRUE, encoding = "utf-8")
```

```{r, echo=TRUE, collapse=FALSE}
print(as_tibble(head(carhyce_brute)))
```


## Dimensions et variables

```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
names(carhyce_brute) # variable names
class(carhyce_brute) # table type (data.frame)
dim(carhyce_brute)   # table dimension
str(carhyce_brute)   # variable type
```

```{r, echo=TRUE, collapse=FALSE}
print(str(carhyce_brute))
```

## Les donn√©es quantitatives

![](./img/datatype_quantitative.webp){width="60%" fig-align="center"} [^2]

[^2]: Artwork by @allison_horst.

## Les donn√©es qualitatives

![](./img/datatype_qualitative.webp){width="80%" fig-align="center"} [^3]

[^3]: Artwork by @allison_horst.

## Nettoyage des colonnes

```{r, echo=TRUE, collapse=FALSE}
# clean column names with janitor
carhyce <- carhyce_brute %>% # %>% = pipe operator from dplyr |> for native pipe
  clean_names() # clean column  names
print(names(carhyce))
```

# Statistiques univari√©es

## Objectifs

- Description des types de variables
- Analyse de la distribution (graphiques et param√®tres)
- Discr√©tisation de variables quantitatives
- D√©tection et traitement des valeurs extr√™mes
- Comparaison √† la loi normale

## nettoyage des lignes et s√©lection des variables

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date
  ungroup() %>%  # ungroup data
  select(surface_bv_km2, continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite, classe_ripisylve,
         nom_her_ou_dom_dominant, debit_plein_bord_m3_s,
         largeur_mouillee_qb_m) # select columns
print(head(carhyce_stat))
```

## Synth√®se analyses univari√©es

![](./img/datatype_summary.webp){width="100%" fig-align="center"}

## Param√®tres de position et de dispersion

Calcul des param√®tres pour les surfaces de bassins versants des stations CARHYCE.

```{r, echo=TRUE, collapse=FALSE}
summary(carhyce_stat$surface_bv_km2)
```
<details>
<summary>Interpr√©tation</summary>
  [La moyenne est pr√®s de 5 fois plus √©lev√© que la m√©diane, elle est m√™me bien plus √©lev√©e que le 3√®me quartile. La distribution est donc asym√©trique √† droite. Nous avons probablement des valeurs extr√™mes qui rendent cette moyenne particuli√®rement √©lev√©e. Le mininum est de 0, on ne peut pas avoir de surface de bassin versant nulle, il y a probablement des erreurs. De m√™me le maximum est sup√©rieur √† 70 000 km2, le protocole CARHYCE est surtout r√©alis√© sur des petits cours d'eau et √† pied, ce maximum repr√©sente plus du double du bassin versant de la Loire.]{style="font-size: 0.7em;"}
</details>

## Histogramme

[Repr√©sentation des effectifs ou fr√©quences d'une variable quantitative divis√©e en classes.]{style="font-size: 0.7em;"}

::: columns
::: {.column width="70%"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# Histogram
hist(carhyce_stat$surface_bv_km2, 
     main = "Surfaces de bassins versants", 
     xlab = "Surface de bassins versants (km2)", col = "lightblue")
```
:::
::: {.column width="30%"}


<details>
<summary>Interpr√©tation</summary>
  [La distribution est tr√®s dissym√©trique √† droite. Cet histogramme ne permet pas de bien repr√©senter la distribution √† cause des valeurs extr√™mes.]{style="font-size: 0.7em;"}
</details>

:::
:::

## Niveau de dissym√©trie

\

![](./img/normality.webp){width="100%" fig-align="center"}

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- rnorm(1000, mean = 0, sd = 1)  # Generate 1000 samples
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- rweibull(1000, shape = 30, scale = 2)  # Generate 1000 samples
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```

```{r, echo=FALSE, eval=FALSE}
# draw an histogram close to a normal distribution with fake data with the normal curve on top
# set.seed(123)  # For reproducibility
fake_data <- data_lognormal <- rlnorm(1000, meanlog = 2, sdlog = 0.8)
h <- hist(fake_data, col = "lightblue", main = "", xlab = "Fake data", breaks = 30)
xfit <- seq(min(fake_data), max(fake_data), length = 40)
yfit <- dnorm(xfit, mean = mean(fake_data), sd = sd(fake_data))
yfit <- yfit * diff(h$mids[1:2]) * length(fake_data)
lines(xfit, yfit, col = "red", lwd = 2)
```


## Boxplot / bo√Æte √† moustache

::: columns
::: {.column width="60%"}

```{r, echo=TRUE, collapse=FALSE}
# Boxplot
boxplot(carhyce_stat$surface_bv_km2, 
        main = "Surfaces de bassins versants", 
        ylab = "Surface de bassins versants (km2)", col = "lightblue")
points(1,mean(carhyce_stat$surface_bv_km2,na.rm=T),pch=16,col="red")
```
:::
::: {.column width="40%"}
![](./img/boxplot.webp){width="100%" fig-align="center"}
:::
:::

## Discr√©tiser une variable quantitative {.smaller}

- **R√®gle de Sturges** : m√©thode de d√©termination du nombre de classes √† utiliser dans un histogramme => avoir un nombre de classes qui soit √† la fois suffisamment grand pour capturer la structure de la distribution des donn√©es, mais pas trop grand pour ne pas perdre de sensibilit√© dans la visualisation.

- En pratique, il est souvent recommand√© de tester plusieurs nombres de classes et de choisir celui qui offre la meilleure repr√©sentation visuelle des donn√©es tout en pr√©servant leur structure.

- Autres m√©thodes : 
    - Effectifs √©gaux : par exemple les quantiles
    - Intervalles √©gaux : par exemple une classe toute les X unit√©s
    - Par seuil de valeurs : par exemple les classes de granulom√©trie

## Discr√©tisation "manuelle"

Par la r√®gle de Sturges
```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
bins <- nclass.Sturges(carhyce_stat$surface_bv_km2) # set breaks with Sturges
carhyce_stat$surface_bv_km2_sturges <- cut(carhyce_stat$surface_bv_km2, 
                                           breaks = bins, 
                                           include.lowest = TRUE, 
                                           right = FALSE) # new column with breaks
```

Par seuil de valeurs
```{r, echo=TRUE, collapse=FALSE, eval=FALSE}
carhyce_stat$surface_bv_km2_breaks <- cut(carhyce_stat$surface_bv_km2, 
                                          breaks = c(0, 50, 100, 500, Inf), 
                                          labels = c("petit", "moyenne", "grand", "tr√®s grand"))
```


## Changement de discr√©tisation et outliers

```{r, echo=TRUE, collapse=FALSE, warning=FALSE, fig.height=5, fig.align='center'}
# plotly interactive histogram with 1000 breaks
plot_ly(x = carhyce_stat$surface_bv_km2, type = "histogram", nbinsx = 1000)
```

## Les outliers ou valeurs extr√™mes

- Valeurs extr√™mes qui ne suivent pas la distribution g√©n√©rale des donn√©es.
- Peuvent √™tre des erreurs de mesure, des valeurs aberrantes ou des valeurs extr√™mes.
- Peuvent fausser les r√©sultats des analyses statistiques qui ne seront plus repr√©sentatives de la population.
- Rend la lecture et l'interpr√©tation des graphiques difficiles.

=> N√©cessite une vraie r√©flexion sur leur origine et leur pertinence dans la suite des analyses statistiques.

## Retrait des valeurs extr√™mes

```{r, echo=TRUE, collapse=FALSE}
# keep the data below the 90th percentile and above 0
carhyce_stat <- carhyce_stat %>% 
  filter(surface_bv_km2 < quantile(carhyce_stat$surface_bv_km2, 0.90, na.rm = TRUE)) %>% 
  filter(surface_bv_km2 > 0)
```

::: columns
::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Histogram with normal curve
h <- hist(carhyce_stat$surface_bv_km2, col = "lightblue", 
          main = "Surface des bassins versants", 
          xlab = "Surface de bassins versants (km2)") 
xfit <- seq(min(carhyce_stat$surface_bv_km2),
            max(carhyce_stat$surface_bv_km2), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat$surface_bv_km2), sd = sd(carhyce_stat$surface_bv_km2)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat$surface_bv_km2) 
lines(xfit, yfit, col = "red", lwd = 2)
```
:::

::: {.column width="50%"}
```{r, echo=TRUE, collapse=FALSE}
# Boxplot
boxplot(carhyce_stat$surface_bv_km2, 
        main = "Surfaces de bassins versants", 
        ylab = "Surface de bassins versants (km2)", 
        col = "lightblue", range = 0)
points(1,mean(carhyce_stat$surface_bv_km2,na.rm=T),pch=16,col="red")
```
:::
:::

## Loi normale ou loi de Gauss {.smaller}

-  Distribution sym√©trique centr√©e sur la moyenne dont la forme est d√©termin√©e par l'√©cart-type.

D√©finie par une fonction de probabilit√© :

- Environ 68% des valeurs sont comprises entre $\mu - \sigma$ et $\mu + \sigma$.
- 95% des valeurs sont comprises entre $\mu - 1.96\sigma$ et $\mu + 1.96\sigma$.

- Tr√®s utilis√©es dans les tests statistiques ou la description de ph√©nom√®nes al√©atoires.

```{r, echo=FALSE, collapse=FALSE, fig.align='center'}
# several density plots on the same graph with dnorm
x <- seq(-4, 4, length=100)
hx <- dnorm(x, mean=0, sd=1)
hx2 <- dnorm(x, mean=-0.5, sd=0.7)
hx3 <- dnorm(x, mean=0.5, sd=0.5)
plot(x, hx, type="l", lwd=2, col="black", xlab="x", ylab="Density", main="Density de distributions normale", ylim=c(0,0.8), xlim=c(-5,5))
lines(x, hx2, lwd=2, col="red")
lines(x, hx3, lwd=2, col="blue")
```

## Coefficient d'assym√©trie de Fisher

```{r, echo=TRUE, collapse=FALSE}
# skewness
e1071::skewness(carhyce_stat$surface_bv_km2, na.rm = TRUE, type = 1) # type 1 = Fisher
```

![](./img/skewness.png){width="100%" fig-align="center"}

## Coefficient d'aplatissement de Fisher

```{r, echo=TRUE, collapse=FALSE}
# kurtosis
e1071::kurtosis(carhyce_stat$surface_bv_km2, na.rm = TRUE, type = 1) # type 1 = Fisher
```

![](./img/kurtosis.png){width="100%" fig-align="center"}

## QQ-plot ou diagramme quantile-quantile

[On compare les quantiles de la distribution observ√©e et ceux de la distribution th√©orique (ici la loi normale).]{style="font-size: 0.7em;"}

::: columns
::: {.column width="70%"}

```{r, echo=TRUE, collapse=FALSE}
# QQ-plot
ggplot(data = carhyce_stat, mapping = aes(sample = surface_bv_km2)) +
  stat_qq_band() +
  stat_qq_line() +
  stat_qq_point() +
  labs(title = "QQ-plot de la surface des bassins versants", x = "Quantiles th√©oriques", y = "Quantiles observ√©s")
```

:::
::: {.column width="30%"}
<details>
<summary>Interpr√©tation</summary>
  [Plus les points sont align√©s sur la droite, plus la distribution observ√©e est proche d'une distribution normale. La distribution observ√©e est tr√®s √©loign√©e d'une distribution normale.]{style="font-size: 0.7em;"}
</details>
:::
:::


## Tests statistiques ? - Principe {.smaller}

- Je lance une pi√®ce de monaie 5 fois et elle tombe 5 fois sur pile => ü§î la pi√®ce doit √™tre truqu√©e.... A partir de combien de pile √† la suite je peux consid√©rer que la pi√®ce est truqu√©e?

- **Partons d'une hypoth√®se : La pi√®ce est bien √©quilibr√©e** (ou j'ai 50% de chance d'avoir pile ou face).

Je vais donc calculer la probabilit√© d'obtenir 5 fois pile si la pi√®ce est √©quilibr√©e (ou dans les conditions de l'hypoth√®se). Je consid√®re que si la probabilit√© d'obtenir 5 fois pile est inf√©rieure √† 5%, je peux rejeter l'hypoth√®se que la pi√®ce est √©quilibr√©e.

\

La loi binomiale permet de calculer ces probabilit√©s. J'ai 3% de chance d'obtenir 5 fois pile si la pi√®ce est √©quilibr√©e. Je peux donc rejeter l'hypoth√®se que la pi√®ce est √©quilibr√©e tout en sachant que j'ai 5% de chance de me tromper. 5% est donc le risque (arbitraire) que j'ai d√©cid√© √† priori, que la pi√®ce soit √©quilibr√©e alors que j'affirme que la pi√®ce est truqu√©e.

```{r, include=FALSE}
# densit√© de probabilit√© de la loi binomiale
n <- 5  # Nombre de lancers
p <- 0.5  # Probabilit√© de succ√®s (pile)
# Valeurs possibles de succ√®s
x <- 0:n
# Densit√© de probabilit√©
prob <- dbinom(x, size = n, prob = p)
# Repr√©sentation graphique
plot(x, prob, type = "h", lwd = 2, col = "blue",
     xlab = "Nombre de succ√®s", ylab = "Probabilit√©", ylim = c(0, 0.5),
     main = "Densit√© de probabilit√© de la loi binomiale")
# ajouter les valeurs
text(x, prob, labels = round(prob, 2)*100, pos = 3)
```

## Tests statistiques ? - test d'ad√©quation {.smaller}

Partons d'une hypoth√®se :

- $H_0$ : la distribution suit une loi normale.
- $H_1$ : la distribution ne suit pas une loi normale.

**Quel est la probabilit√© d'obtenir notre distribution observ√©e si la distribution √©tait normale?**

On compare notre distribution observ√©e √† une distribution th√©orique (ici la loi normale). Si notre distribution observ√©e √† tr√®s peu de chance d'√™tre obtenue si la distribution √©tait normale, on peut rejeter $H_0$. Si nos observations appartiennent aux r√©sultats qui ont une chance d'√™tre obtenus si $H_0$ est vraie, on peut accepter $H_0$ (ou $H_0$ reste cr√©dible).

\

Le "tr√®s peu de chance" est repr√©sent√© par le risque $\alpha$ (seuil de significativit√© ou risque de premier esp√®ce), souvent de 5%. Si la probabilit√© d'obtenir notre distribution observ√©e est inf√©rieure √† 5% si la distribution √©tait normale, on peut rejeter $H_0$. 
On peut choisir un risque $\alpha$ plus faible selon notre confiance dans nos r√©sultats et l'enjeu du risque. Imaginez que l'on teste l'efficacit√© d'un m√©dicament d'une maladie grave... as t'on envie d'avoir 1 chance sur 20 de se tromper?

## Tests statistiques ? - p-value {.smaller}

- Tous les tests se concluent par une p-value. On la compare au seuil de significativit√© $\alpha$ annonc√©e avant le test.

- Interpr√©tation de la p-value : $p=0.15$ signifie que l'on a 15% de chance d'obtenir les donn√©es observ√©es si $H_0$ est vraie (ou si la distribution √©tait normale). $p$ n'est pas un risque de se tromper mais une mesure de la significativit√© du r√©sultat (ou une probabilit√© √† post√©riori). Le risque de se tromper se choisi √† priori et non √† post√©riori du test.

- p-value < $\alpha$ : on rejette $H_0$ et on accepte $H_1$ avec le riques de se tromper de $\alpha$. La diff√©rence observ√©e est significative.
- p-value > $\alpha$ : on accepte $H_0$ **mais** on ne peut pas dire que $H_0$ est vraie ü§Ø. 

*Petite subtilit√©, le fait d'accepter $H_0$ ne signifie pas que $H_0$ soit vraie, mais que sur la base des donn√©es observ√©es rien ne permet de conclure qu'elle soit fausses.*

## Tests statistiques ? - erreur! {.smaller}

Lors d'un test statistique, on peut faire deux types d'erreurs :

- **Erreur de type I** : Risque de rejeter $H_0$ alors qu'elle est vraie. Risque $\alpha$ => on affirme une diff√©rence alors qu'en r√©alit√© il n'y en a pas.
- **Erreur de type II** : Risque de ne pas rejeter $H_0$ alors qu'elle est fausse. Risque $\beta$ => on affirme qu'il n'y a pas de diff√©rence alors qu'en r√©alit√© il y en a une. On se sait pas calculer ce risque, on ne peut donc pas affirmer $H_0$.

Le risque $\beta$ est d'autant plus petit que l'√©chantillon est important. La puissance d'un test, $1 - \beta$, est la probabilit√© de rejeter $H_0$ alors qu'elle est fausse. Pour d√©tecter une faible diff√©rence, il faux un test puissant, soit un √©chantillon suffisamment grand (voir la vid√©os de [Tierry Ancelle](https://www.youtube.com/watch?v=qWxJkq7QFWY) pour une tr√®s bonne illustration).

![](./img/test_rules.webp){width="100%" fig-align="center"}

## Tests statistiques ? - ressources

Des vid√©os tr√®s p√©dagogiques de [Tierry Ancelle](https://www.epiter.org/page/2366997-lecons-epiteriennes-en-ligne){target="_blank"} : 

- [Principes des tests statistiques](https://www.youtube.com/watch?v=qWxJkq7QFWY){target="_blank"}
- [Le petit p](https://www.youtube.com/watch?v=X6gPReE1w2g){target="_blank"}

Sur la description, l'histoire et l'utilisation des tests statistiques : 

- L'ouvrage en ligne de Denis Poinsot ["Les statistiques pour les statophobes" (2004)](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf){target="_blank"}

## Test de normalit√© - pr√©caution / utilisation

- Les tests de normalit√© sont sensibles √† la taille de l'√©chantillon : 
    - Pour un √©chantillon de taille r√©duite, les tests de normalit√© peuvent √™tre biais√©s.
    - Pour un √©chantillon de taille importante, les tests de normalit√© peuvent √™tre trop sensibles.

- Souvent utilis√© au pr√©lable d'autres tests statistiques dit param√©triques : 
  - Shapiro-Wilk => meilleur pour de petits √©chantillons (<2000)
  - Kolmogorov-Smirnov => grands √©chantillons (>2000)
  - Anderson-Darling => grands √©chantillons (>2000)

## Test de normalit√©

::: panel-tabset

### Shapiro-Wilk
```{r, echo=TRUE, collapse=FALSE}
shapiro.test(carhyce_stat$surface_bv_km2)
```

### Anderson-Darling
```{r, echo=TRUE, collapse=FALSE}
ad.test(carhyce_stat$surface_bv_km2)
```

### Kolmogorov-Smirnov
```{r, echo=TRUE, collapse=FALSE}
ks.test(carhyce_stat$surface_bv_km2, "pnorm", mean = mean(carhyce_stat$surface_bv_km2), sd = sd(carhyce_stat$surface_bv_km2))
```
:::

- $H_0$ : la variable suit une distribution normale.
- $H_1$ : la variable ne suit pas une distribution normale.

- p-value < 2.2e-16 < 0.05, On peut rejeter $H_0$ et valider $H_1$ avec une probabilit√© de se tromper de 5%.

## Distribution des classes de ripisylve

```{r, echo=TRUE, collapse=FALSE}
# Table
print(table(carhyce_stat$classe_ripisylve))
```

```{r, echo=TRUE, collapse=FALSE}
# Create a frequency table
freq_table <- carhyce_stat %>%
  group_by(classe_ripisylve) %>%
  summarise(count = n()) %>%
  mutate(freq_percent = count / sum(count) * 100,
         cum_freq = cumsum(count),
         cum_freq_percent = cumsum(freq_percent))
print(freq_table)
```

## Diagramme en secteur

```{r, echo=TRUE, collapse=FALSE}
# Pie chart
pie(table(carhyce_stat$classe_ripisylve), main = "R√©partition des classes de ripisylve")
```

## Cheat code exploration de donn√©es

```{r, echo=TRUE, collapse=FALSE}
print(skim(carhyce_stat$surface_bv_km2))
```

```{r, echo=TRUE, collapse=FALSE, results='hide'}
# makeDataReport(carhyce_stat)
```

# Statistiques bivari√©es

## Objectifs

- Pouvoir d√©crire la relation qui peut exister entre deux variables.
- Utiliser les bons outils selon la nature des variables √† comparer.
- Evaluer le type, l'intensit√© et le sens d'une relation entre deux variables quantitatives.

## Reprenons nos donn√©es

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  filter(surface_bv_km2 < quantile(carhyce$surface_bv_km2, 0.90, na.rm = TRUE)) %>% # keep surface_bv_km2 data below the 90th percentile
  filter(debit_plein_bord_m3_s < quantile(carhyce$debit_plein_bord_m3_s, 0.95, na.rm = TRUE)) %>%
  filter(largeur_mouillee_qb_m < quantile(carhyce$largeur_mouillee_qb_m, 0.975, na.rm = TRUE)) %>%
  filter(vitesse_moyenne_qb_m_s < quantile(carhyce$vitesse_moyenne_qb_m_s, 0.975, na.rm = TRUE)) %>%
  filter(d50_mm < quantile(carhyce$d50_mm, 0.99, na.rm = TRUE)) %>%
  # group categories continuite_ripisylve_rive_gauche and continuite_ripisylve_rive_droite :"espac√©e" = "bosquets √©parses" + "espac√©e-r√©guli√®re" + "isol√©e"
  mutate(continuite_ripisylve_rive_gauche = ifelse(continuite_ripisylve_rive_gauche %in% c("bosquets √©parses", "espac√©e-r√©guli√®re", "isol√©e"), "espac√©e", continuite_ripisylve_rive_gauche),
         continuite_ripisylve_rive_droite = ifelse(continuite_ripisylve_rive_droite %in% c("bosquets √©parses", "espac√©e-r√©guli√®re", "isol√©e"), "espac√©e", continuite_ripisylve_rive_droite)) %>%
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         debit_plein_bord_m3_s,
         largeur_mouillee_qb_m,
         vitesse_moyenne_qb_m_s,
         d50_mm,
         nombre_transect) # select columns
```

## Qualitatif VS qualitatif - Tableau de contingence

![](./img/contingency_table.png){width="100%" fig-align="center"}

[Distribution jointe de deux variables qualitatives (ou quantitatives discr√©tis√©es)]{style="font-size: 0.7em;"}

[On compte les individus pour chaque modalit√© des deux variables]{style="font-size: 0.7em;"}

[Distribution conditionnelle : ]{style="font-size: 0.7em;"}

[   - en ligne : quelle distribution de X des cours d'eau normand]{style="font-size: 0.7em;"}

[   - en colonne : quelle distribution de Y des cours d'eau de bonne qualit√©]{style="font-size: 0.7em;"}

## Tableau de contingence

::: panel-tabset
### Rbase

```{r, echo=TRUE, collapse=FALSE}
# Rbase method contingency table
tab <- table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite)
tab_mag <- addmargins(tab) # margins (effectifs marginaux)
print(tab_mag)
```

### gmodels effectifs

```{r, echo=TRUE, collapse=FALSE, results='hide'}
contingency_table <- CrossTable(carhyce_stat$continuite_ripisylve_rive_gauche, 
                                 carhyce_stat$continuite_ripisylve_rive_droite, 
                                 prop.chisq = FALSE, prop.t = TRUE, prop.r = TRUE, prop.c = TRUE)
```

```{r, echo=TRUE, collapse=FALSE}
print(contingency_table$t)
```
:::

## Effectif partiels (fr√©quence)

::: panel-tabset
### total

[Effectifs partiels sur effectif total (le total des fr√©quences = 1) : X% des individus appartiennent aux modalit√©s truc et bidule **ou**  X % des cours d'eau ont une eau de bonne qualit√© et sont en Normandie]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite
print(round(contingency_table$prop.tbl, 3)) # or prop.table(x, y)
```

### ligne

[Effectifs partiels sur effectif marginal (fr√©quence conditionnelle, le total de chaque ligne = 1) : X% des cours d'eau Normands ont une eau de mauvaise qualit√©]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite
print(round(contingency_table$prop.row, 3)) # or prop.table(x, y, margin = 1)
```

### colonne

[Effectifs partiels sur effectif marginal (fr√©quence conditionnelle, le total de chaque colonne = 1) : X% des cours d'eau de bonne qualit√© sont Normands]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# x = rive gauche, y = rive droite (ou fr√©quence conditionnelle)
print(round(contingency_table$prop.col, 3)) # or prop.table(x, y, margin = 2)
```
:::

## Diagramme en barre et mosaique

::: panel-tabset
### Group√©

```{r, echo=TRUE, collapse=FALSE, fig.height=4}
ggplot(carhyce_stat, aes(x=factor(continuite_ripisylve_rive_gauche), fill=factor(continuite_ripisylve_rive_droite))) +
  geom_bar(position = "dodge") +
  labs(x = "Ripisylve rive gauche", y = "Effectif", fill = "Ripisylve rive droite") +
  theme_minimal()
```

### Empil√©

```{r, echo=TRUE, collapse=FALSE, fig.height=4}
ggplot(carhyce_stat, aes(x=factor(continuite_ripisylve_rive_gauche), fill=factor(continuite_ripisylve_rive_droite))) +
  geom_bar(position = "stack") +
  labs(x = "Ripisylve rive gauche", y = "Effectif", fill = "Ripisylve rive droite") +
  theme_minimal()
```

### Mosaique

```{r, echo=TRUE, collapse=FALSE}
mosaicplot(table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite), xlab = "Rive gauche", ylab = "Rive droite", main = "")
```
:::

## Test du Chi2 d'ind√©pendance

- V√©rifier un lien de d√©pendance statistiquement significatif entre deux variables qualitatives.

- Conditions d'application : 
    - Les variables doivent √™tre qualitatives.
    - Les effectifs combin√©s des modalit√©s des variables $\geq$ 5 (du moins pour 80% des effectifs joints).
    
- Hypoth√®ses : 
    - $H_0$ : les variables sont ind√©pendantes.
    - $H_1$ : les variables sont d√©pendantes.

## Chi2 - calcul des effectifs attendus.

Tableau de contingence observ√© :
```{r}
tab_mag
```
- Quelles sont les effectifs joints attendus si les deux variables sont ind√©pendantes ?

- Les effectifs attendus suivent la distribution marginale des variables pour respecter les r√©partitions totales de chaque variable.

- La formule est le produit des effectifs marginaux divis√© par le total des effectifs.

## Chi2 - calcul des effectifs attendus.

Tableau de contingence observ√© :
```{r}
tab_mag
```
Exemple : 

- Le nombre de stations avec une ripisyle espac√©e en rive gauche doit rest√© de 492 (effectif marginal) mais peut √™tre r√©parti diff√©remment dans les modalit√©s de la rive droite.

- L'effectif joint attendu entre espac√©e en rive gauche et continue en rive droite : $\frac{492 \times 664}{1834} = 178$

## Chi2 - effectif calcul√© sous $H_0$

[Effectif calcul√© sous $H_0$]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# run chi2 test
chi2_ripisylve <- chisq.test(table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$continuite_ripisylve_rive_droite))
print(round(chi2_ripisylve$expected[,1:4], 0))
```
Le $\chi^2$ repr√©sente la diff√©rence des deux tables que l'on compare au $\chi^2$ critique pour d√©terminer si on peut rejeter $H_0$ avec un une probabilit√© d'erreur d√©finie (5% g√©n√©ralement). Voir [table de $\chi^2$ par Fabrice Larribe](http://fabricelarribe.uqam.ca/resources/Tables/Table-Chi2-Print.pdf){target="_blank"}

## Chi2 - interpr√©tation

```{r, echo=TRUE, collapse=FALSE}
print(chi2_ripisylve)
```
- La p-value repr√©sente la probabilit√© d'obtenir un r√©sultat aussi extr√™me que celui observ√©, dans les conditions de $H_0$.

- Cette situation est tr√®s improbable. On peut rejeter $H_0$ et valider $H_1$ avec une probabilit√© de se tromper de $2.2 \times 10^{-16} \times 100$%.

## Qualitatif VS Quantitatif - Discr√©tisation

Discr√©tiser une variable quantitative, exemple par seuil de valeurs.

```{r, echo=TRUE, collapse=FALSE}
# create breaks [0,5), [5,10), [10,20), [20,30), [30,40), [>40]
largeurs_breaks <- c(0, 5, 10, 20, 30, 40, Inf)
carhyce_stat$largeur_mouillee_qb_m_breaks <- cut(carhyce_stat$largeur_mouillee_qb_m, 
                                                  breaks = largeurs_breaks, 
                                                  include.lowest = TRUE, 
                                                  right = FALSE) # new column with breaks
tab <- table(carhyce_stat$continuite_ripisylve_rive_gauche, carhyce_stat$largeur_mouillee_qb_m_breaks) # contingency table
addmargins(tab) # with margins (effectifs marginaux)
```

## Description de la distribution par modalit√©

::: panel-tabset
### Indicateurs

```{r, echo=TRUE, collapse=FALSE}
summary_table <- carhyce_stat %>%
  group_by(continuite_ripisylve_rive_gauche) %>% 
  dplyr::summarize(
    Mean = mean(largeur_mouillee_qb_m, na.rm = TRUE),
    Median = median(largeur_mouillee_qb_m, na.rm = TRUE),
    StdDev = sd(largeur_mouillee_qb_m, na.rm = TRUE)
  )
print(summary_table)
```

### Boxplot

```{r, echo=TRUE, collapse=FALSE, fig.height=3.5}
ggplot(carhyce_stat, aes(x = factor(continuite_ripisylve_rive_gauche), y = largeur_mouillee_qb_m, fill = factor(continuite_ripisylve_rive_gauche))) +
  geom_boxplot() +
  labs(x = "Ripisylve rive gauche", y = "Largeur mouill√©e (m)", fill = "Ripisylve rive gauche") +
  theme_minimal()
```
:::

## Quantitatif VS quantitatif

La repr√©sentation par nuage de point, avec en X plut√¥t la variable explicative et en Y la variable expliqu√©e.

```{r, echo=TRUE, collapse=FALSE, fig.align='center', fig.height=4}
plot <- ggplot(carhyce_stat, aes(x = debit_plein_bord_m3_s, y = largeur_mouillee_qb_m)) +
  geom_point() +
  labs(x = "D√©bit de plein bord (m3/s)", y = "Largeur mouill√©e plein bord (m)") +
  theme_minimal()
  # + geom_smooth(method="lm", col="red") # d√©commenter cette ligne pour ajouter la r√©gression lin√©aire
plot
```

## R√©gression ?

::: panel-tabset
### Lin√©aire

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red")
```


### Polynomiale

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red", formula = y ~ poly(x, 2))
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE}
plot + geom_smooth(method="lm", col="red", formula = y ~ log(x) + x)
```
:::

## Covariance {.smaller}

**Evalue dans quelle mesure les variations de deux variables sont simultan√©es ou non.**

- "+" : les √©carts entre les valeurs et leur moyenne ont tendance a √™tre de m√™me signe.
- "-" : les √©carts entre les valeurs et leur moyenne ont tendance a √™tre de signe oppos√©.
- "0" : les √©carts entre les $Xi$ et leur moyenne et les √©carts entre les $Yi$ et leur moyenne n'ont aucun lien entre eux.

**Attention** : 

- Sa dimension est le produit des dimensions des variables (e.g. euros et ann√©es), elle est donc difficile √† interpr√©ter.

- Davantage un outil qui permet d'effectuer d'autres calculs comme la corr√©lation de Person qu'un indicateur utilis√© pour l'interpr√©tation (c'est un peu comme la variance et l'√©cart type).

## Coefficient de corr√©lation lin√©aire de Pearson {.smaller}

**Evalue le degr√© de d√©pendance lin√©aire entre deux variables quantitatives. Le r√©sultat d√©pend de la qualit√© de l'ajustement affine obtenu par une r√©gression lin√©aire.**

**Intensit√© :**

- Proche de 1 (ou -1) = forte d√©pendance des variables
- Proche de 0 = ind√©pendance des variables

**Sens :**

- ">0" = les variables √©voluent dans le m√™me sens
- "<0" = les variables √©voluent dans le sens oppos√©.

- Plus on s'√©loigne de 0 plus les deux variables sont fortement corr√©l√©es lin√©airement. 
- Le signe indique le sens de la relation.

## Quelques exemples de corr√©lation

![](./img/pearson_corr_examples.png){width="100%" fig-align="center"}


## Coefficient de d√©termination

**Le coeffient de corr√©lation de Pearson au carr√©. Il d√©termine le pourcentage de variation de Y imputable √† X.**

\

$R^2$% des variations de Y s'expliquent par X.

Par exemple si $R^2 = 0.35$, 35% des variations de la largeur mouill√©e s'expliquent par le d√©bit.

\

**Attention :** 

- Corr√©lation $\neq$ causalit√©! [Quelques beaux exemples](https://tylervigen.com/spurious-scholar){target="_blank"}
- Multicolin√©arit√©, quand plusieurs variables explicatives ont des liens de corr√©lation entre elles!

## Le Quartet d'Anscombe

![](./img/quartet_anscombe.png){width="100%" fig-align="center"}

- Moralit√© : toujours visualiser les donn√©es avant de les analyser ! üßê

## Coefficient de corr√©lation de Spearman

- C'est le coefficient de Pearson appliqu√© aux rangs des variables.

- Similaire au coefficient de Pearson mais ne suppose pas de relation lin√©aire entre les variables. Il √©value la relation monotone, qui ont tendance √† se d√©placer dans la m√™me direction relative, entre deux variables ind√©pendamment de la forme.

- L'interpr√©tation est similaire √† celle du coefficient de Pearson.

## Calcul des coefficients de corr√©lation

```{r, echo=TRUE, collapse=FALSE}
# r Pearson correlation
print(paste0("r = ", round(cor.test(carhyce_stat$largeur_mouillee_qb_m, carhyce_stat$debit_plein_bord_m3_s, method = "pearson")$estimate, 2)))
# rho Spearman correlation
print(paste0("rho = ", round(cor.test(carhyce_stat$largeur_mouillee_qb_m, carhyce_stat$debit_plein_bord_m3_s, method = "spearman")$estimate, 2)))
```
Int√©r√™t de calculer les deux coefficients :

- r>$\rho$ : pr√©sence √©ventuelle de valeurs exceptionnelles.
- r<$\rho$ : pr√©sence √©ventuelle d'une relation non lin√©aire.

## Lire le r√©sultat d'un mod√®le de r√©gression lin√©aire {.smaller}

::: columns
::: {.column width="50%"}

```{r, echo=TRUE, collapse=FALSE}
model_lineaire <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s, 
                     data = carhyce_stat)
summary(model_lineaire)
```

:::
::: {.column width="50%"}
- R√©sidus : diff√©rence entre les valeurs observ√©es et les valeurs pr√©dites par le mod√®le.
- Erreur standard des r√©sidus : √©cart-type des r√©sidus (ou la dispersion autour de la droite)
- Coefficients avec erreur standard et test de significativit√©  :

  - Estimate (Intersept) : b ou l'ordonn√©e √† l'origine
  - Estimate (Variable) : a ou la pente

- R-squared : coefficient de d√©termination

:::
:::

## Comparaison des mod√®les r√©gressions

::: panel-tabset

### Lin√©aire

```{r, echo=TRUE, collapse=FALSE}
model_lineaire <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s, data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_lineaire)[1], 2), " + ", round(coef(model_lineaire)[2], 2), "x"))
# R2
print(paste0("R2 = ", round(summary(model_lineaire)$r.squared, 2)))
# Residual standard error
print(paste0("S = ", round(summary(model_lineaire)$sigma, 2)))
```

### Polynomiale
```{r, echo=TRUE, collapse=FALSE}
# polynomial model (degree 2)
model_poly <- lm(largeur_mouillee_qb_m ~ poly(debit_plein_bord_m3_s, 2), data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_poly)[1], 2), " + ", round(coef(model_poly)[2], 2), "x + ", round(coef(model_poly)[3], 2), "x^2"))
# Residual standard error
print(paste0("S = ", round(summary(model_poly)$sigma, 2)))
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE}
# logarithmic model
model_log <- lm(largeur_mouillee_qb_m ~ log(debit_plein_bord_m3_s), data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_log)[1], 2), " + ", round(coef(model_log)[2], 2), "log(x)"))
# Residual standard error
print(paste0("S = ", round(summary(model_log)$sigma, 2)))
```
:::

## Analyse des r√©sidus {.smaller}

::: panel-tabset

### Lin√©aire

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_lineaire, which = 1)
```

### Polynomiale

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_poly, which = 1)
```

### Logarithmique

```{r, echo=TRUE, collapse=FALSE, fig.width=15}
plot(model_log, which = 1)
```

:::

- Les r√©sidus doivent √™tre dispers√©s al√©atoirement autour de z√©ro. La pr√©sence d‚Äôune tendance (lin√©aire ou non) indique des effets syst√©matiques ignor√©s par le mod√®le.

## Homos√©dasticit√© vs H√©t√©ros√©dasticit√©

\

![](./img/homosedasticite.webp)

## Normalit√© des r√©sidus {.smaller}

```{r, echo=TRUE, collapse=FALSE, fig.height=3.2}
par(mfrow=c(1,2))
plot(model_lineaire, which = 2)
hist(model_lineaire$residuals, breaks = 100, main = "Histogramme des r√©sidus", xlab = "R√©sidus")
```
<details>
  <summary>Analyse de la normalit√©</summary>
- Q-Q plot => d√©tection des d√©viations syst√©matiques de la normalit√© des r√©sidus. La distribution des r√©sidus pr√©sente une dissym√©trie √† droite.
- Notre mod√®le a une surrepr√©sentation d'√©carts √† la moyenne √©lev√©s.
</details>

## R√©gression lin√©aire multiple

Plusieurs variables explicatives pour une variable expliqu√©e.

```{r, echo=TRUE, collapse=FALSE, out.height= 1}
# multiple linear regression with two variables
model_multiple <- lm(largeur_mouillee_qb_m ~ debit_plein_bord_m3_s + 
                       vitesse_moyenne_qb_m_s + d50_mm + 
                       nombre_transect, data = carhyce_stat)
# equation
print(paste0("y = ", round(coef(model_multiple)[1], 2), " + ", 
                round(coef(model_multiple)[2], 2), "x1 + ", 
                round(coef(model_multiple)[3], 2), "x2 + ", 
                round(coef(model_multiple)[4], 2), "x3"))
```

## R√©gression lin√©aire multiple - interpr√©tation {.smaller}

::: columns
::: {.column width="50%"}

```{r, echo=TRUE, collapse=FALSE}
summary(model_multiple)
```

:::
::: {.column width="50%"}

<details>
  <summary>Interpr√©tation</summary>
- Le d√©bit, la vitesse, la granulom√©trie et le nombre de transect expliquent 56% de la variation de la largeur mouill√©e.
- Les variables explicatives ont toutes un effet l√©g√®rement positif sur la largeur mouill√©e √† l'exception de la vitesse qui a un effet fortement n√©gatif.
- Les variables ont un effet significatif sur la largeur mouill√©e sauf le nombre de transect.
</details>

:::
:::

## R√©gression lin√©aire multiple - synth√®se

```{r, echo=TRUE, collapse=FALSE}
model_multiple %>%
  tbl_regression(intercept = TRUE)
```

## R√©gression lin√©aire multiple - graphique en for√™t

```{r, echo=TRUE, collapse=FALSE}
# forest plot
ggstats::ggcoef_model(model_multiple)
```

## Matrice de nuage de points

```{r, echo=TRUE, collapse=FALSE}
pairs(carhyce_stat[, c("vitesse_moyenne_qb_m_s", "debit_plein_bord_m3_s", "largeur_mouillee_qb_m", "d50_mm")])
```

## Corr√©lations crois√©es

```{r, echo=TRUE, collapse=FALSE}
pearson <- cor(carhyce_stat[, c("vitesse_moyenne_qb_m_s", "debit_plein_bord_m3_s", "largeur_mouillee_qb_m", "d50_mm")], method = "pearson")
pearson
```

[- Les corr√©lations lin√©aire les plus fortes sont entre le d√©bit et la largeur mouill√©e et entre la vitesse et le d√©bit. Le D50 est peu corr√©l√© avec les autres variables (un peu avec la largeur mouill√©e). ]{style="font-size: 0.7em;"}

[- Si on prend la largeur mouill√©e comme variable expliqu√©e, le d√©bit et le D50 semblent √™tre des variables explicatives int√©ressantes.]{style="font-size: 0.7em;"}

## Corr√©lations crois√©es - graphique

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
corrplot(pearson, 
         type = "upper",
         diag = FALSE,
         tl.col = "dark grey",
         tl.srt = 45)
```

# Comparaison de jeux de donn√©es

## Hypoth√®ses et probl√©matiques

Hypoth√®ses : 

- Les stations CARHYCE sont repr√©sentatives de l'√©tat des rivi√®res fran√ßaises pour les petits bassins versants (<100 km2).
- Je peux distinguer les stations de montagne des stations de plaine par leur classification g√©ographique.

Probl√©matiques :

- Les rivi√®res de montagne ont-elles des caract√©ristiques diff√©rentes des rivi√®res de plaine pour les petits bassins versants ?


## Reprenons nos donn√©es {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  filter(surface_bv_km2 < 100) %>% # keep surface_bv_km2 data below 100 km2
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         score_ripisylve,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         coefficient_de_sinuosite,
         coefficient_rugosite,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2,
         modele_reference_img,
         montagne_plaine) %>%  # select columns
  na.omit() # remove NA values
```

## Th√©or√®me central limite

- Prennons un grand nombre d'√©chantillons de taille n d'une distribution non normale de moyenne $\mu$ et d'√©cart-type $\sigma$. Quelle est la distribution des moyennes si on effectue de nombreux tirage al√©atoire de taille n?

- Illustration dans le [Grimoire de Lise Vaudor](http://perso.ens-lyon.fr/lise.vaudor/grimoireStat/_book/decrire-une-variable.html#loi-normale){target="_blank"}

- La moyenne d'un grand nombre d'√©chantillons (n>30) de distribution quelconque de taille n suit une distribution normale, soit $\bar{x} \sim N(\mu, \frac{\sigma}{\sqrt{n}})$

::: aside

$\mu$ = moyenne de la population, $\sigma$ = √©cart-type de la population, $n$ = taille de l'√©chantillon

:::

## Erreur standard {.smaller}

- L'√©cart type est un indicateur de la dispersion des valeurs d'un √©chantillon (ou d'une population) autour de la moyenne.

- L'erreur standard est l'√©cart type d'un param√®tre (moyenne, pourcentage, etc.). Notre moyenne de notre jeu de donn√©es (ou √©chantillon) n'est qu'une estimation de la moyenne de la population. Si on refaisait l'√©chantillonnage, on obtiendrait une autre moyenne √† cause des fluctuations d'√©chantillonnage. L'erreur standard est l'√©cart type de ces moyennes.

- L'erreur standard de la moyenne d'un √©chantillon peut √™tre calcul√© : $\frac{\sigma}{\sqrt{n}}$. Il a donc la particularit√© de diminuer avec la racine carr√©e de la taille de l'√©chantillon, contrairement √† l'√©cart type d'un √©chantillon.

::: aside

Une explication compl√®te et tr√®s p√©dagogique est dans l'annexe 3 des [Statistiques pour statophobes (2004) de Denis Poinsot](https://perso.univ-rennes1.fr/denis.poinsot/Statistiques_%20pour_statophobes/STATISTIQUES%20POUR%20STATOPHOBES.pdf).

:::

## Intervalle de confiance de la moyenne (n>30, distribution quelconque) {.smaller}

- Un intervalle de confiance d'un param√®tre est un intervalle dans lequel on estime que le param√®tre se trouve avec une certaine probabilit√©.

- Selon le th√©or√®me central limite, la moyenne calcul√© sur un grand √©chantillon $\bar x$ suit une loi approximativement normale de moyenne (de la population) $\mu$ et d'√©cart type (ou erreur standard) $\frac{\sigma}{\sqrt{n}}$.

- Nous avons un grand √©chantillon, l'√©cart-type de l'√©chantillon est donc une bonne estimation de l'√©cart-type de la population. 

- Dans une distribution normale, 95% des valeurs se trouvent dans l'intervalle $IC_{95\%} = [\bar x-1.96\frac{s}{\sqrt{n}},\bar x+1.96\frac{s}{\sqrt{n}}]$. La moyenne de l'√©chantillon a 95% de chance de se trouver dans cet intervalle. On peut remplacer 1.96 par une autre valeur critique de la loi normale avec son niveau de confiance associ√© ($IC_{99\%}$, la valeur critique est de 2.575).

::: aside

$\mu$ = moyenne de la population, $\bar x$ = moyenne de l'√©chantillon, $\sigma$ = √©cart-type de la population, $s$ = √©cart-type de l'√©chantillon, $n$ = taille de l'√©chantillon

:::

## Intervalle de confiance de la moyenne (n<30, distribution normale) {.smaller}

- La distribution est normale mais on ne peut plus remplacer l'√©cart-type de la population $\sigma$ par l'√©cart-type de l'√©chantillon $s$. L'√©cart-type de la population est alors remplac√© par le $t$ de Student pour $n-1$ degr√©s de libert√© (df ou degrees of freedom en anglais). 

- Les degr√©es de libert√© sont le nombre de valeurs susceptible de varier dans un calcul statistique. Les observations d'un √©chantillon peuvent vari√©es d'un √©chantillon √† l'autre, refl√©tant la variabilit√© inh√©rente des donn√©es dans la population. Les degr√©s de libert√© sont un concept statistique qui quantifie combien de valeurs peuvent encore varier apr√®s que certaines restrictions ont √©t√© appliqu√©es. Dans le cas de l'√©chantillon, si vous connaissez la moyenne $\bar x$, toutes les valeurs de l'√©chantillon doivent s'ajuster pour que la somme totale des √©carts √† la moyenne soit nulle. Cela signifie que si n est la taille de l'√©chantillon, seulement n-1 valeurs peuvent varier ind√©pendamment, la derni√®re est d√©termin√©e par les autres.

- L'intervalle de confiance est alors pour $IC_{95\%} = [\bar x-t_{0.975}\frac{s}{\sqrt{n}},\bar x+t_{0.975}\frac{s}{\sqrt{n}}]$. On peut remplacer $t_{0.975}$ par n'importe quelle valeur critique de la loi de Student pour son niveau de confiance associ√©.

## Intervalle de confiance de la moyenne (n>30 ou distribution normale) - calcul

```{r, echo=TRUE, collapse=FALSE}
# mean confidence interval for the sample with 95% confidence level
t.test(carhyce_stat$largeur_mouillee_qb_m, 
       conf.level = 0.95)
```

## Intervalle de confiance de la moyenne (n<30, distribution non normale) {.smaller}

- La m√©thode du bootstrap : on simule d'une mani√®re it√©rative et inductive une multitude d'√©chantillons analogues √† l'√©chantillon initial. On calcule la moyenne de chaque √©chantillon et on obtient la distribution des moyennes. L'intervalle de confiance est alors d√©termin√© par les quantiles de cette distribution.

```{r, echo=TRUE, collapse=FALSE}
# sample 20 values from the population
sample_largeur <- sample(carhyce_stat$largeur_mouillee_qb_m, 20)
print(paste0("Moyenne du sous √©chantillon = ", mean(sample_largeur)))
```
```{r, echo=TRUE, collapse=FALSE}
bootstat <- function(x, i) mean(x[i]) # bootstrap function
# mean confidence interval for the sample with 95% confidence level
mean_ci_sample <- boot(data = sample_largeur, 
                       statistic = bootstat, R = 1000)
boot.ci(mean_ci_sample, type = "basic", conf = 0.95)
```
## Intervalle de confiance d'une m√©diane

- La m√©thode du bootstrap peut √™tre utilis√©e.

```{r, echo=TRUE, collapse=FALSE}
print(paste0("M√©diane = ", median(carhyce_stat$largeur_mouillee_qb_m)))
bootstat <- function(x, i) median(x[i]) # bootstrap function
# mean confidence interval for the sample with 95% confidence level
median_ci_sample <- boot(data = carhyce_stat$largeur_mouillee_qb_m, 
                         statistic = bootstat, R = 1000)
boot.ci(median_ci_sample, type = "basic", conf = 0.95)
```

```{r, echo=FALSE, include=FALSE}
# Median confidence interval for symmetric distribution 
wilcox.test(carhyce_stat$largeur_mouillee_qb_m, conf.int = TRUE)
```

## Intervalle de confiance - synth√®se

![](./img/ic_summary.webp){width="100%" fig-align="center"}

## Test de comparaison des moyennes {.smaller}

Des tests de comparaison de moyennes peuvent √™tre effectu√©s pour tester si les moyennes de deux √©chantillons sont significativement diff√©rentes : 

- Tests param√©triques (distribution normale ou n>30) :

  - Test de Student (t-test) : comparaison de moyennes de deux √©chantillons de variances √©gales.
  - Test de Welch : comparaison de moyennes de deux √©chantillons de variances diff√©rentes.
  
Si la distribution est tr√®s dissym√©trique malgr√©s un √©chantillon >30, un test non param√©trique est pr√©f√©rable.

- Tests non param√©triques (distribution non-normale **et** n<30) : test de Wilcoxon-Mann-Whitney.

Les tests ont des variantes selon l'ind√©pendance des variables (√©chantillons appari√©s ou non).

"two.sided", "less", "greater" sont les options pour le test bilat√©ral, unilat√©ral inf√©rieur ou unilat√©ral sup√©rieur selon si l'on souhaite tester si les moyennes sont diff√©rentes, si une moyenne est inf√©rieure ou si une moyenne est sup√©rieure.

## Choix du test de comparaison des moyennes

![](./img/t-test-diagram.webp){width="100%" fig-align="center"}

<!-- ## Conditions de comparaison des moyennes -->

[*Si la distribution est tr√®s dissym√©trique malgr√©s un √©chantillon >30 => test non param√©trique.]{style="font-size: 0.7em;"}


## Comparaison des stations de plaine et de montagne

**Est-ce que les rivi√®res de montagne ont une granulom√©trie plus grossi√®re que les rivi√®res de plaine?**

\

S√©paration des jeux de donn√©es.

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_montagne <- carhyce_stat %>% filter(montagne_plaine == "montagne")
carhyce_stat_montagne_mean = mean(carhyce_stat_montagne$d50_mm, na.rm = TRUE)
print(paste0("Moyenne D50 station de montage = ", round(carhyce_stat_montagne_mean, 2)))
```

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_plaine <- carhyce_stat %>% filter(montagne_plaine == "plaine")
carhyce_stat_plaine_mean = mean(carhyce_stat_plaine$d50_mm, na.rm = TRUE)
print(paste0("Moyenne D50 station de montage = ", round(carhyce_stat_plaine_mean, 2)))
```
## V√©rification des distributions - code

```{r, echo=TRUE, eval=FALSE}
# histogram with normal curve
par(mfrow=c(1,2))
h <- hist(carhyce_stat_montagne$d50_mm, col = "lightblue", main = "Montagne", 
          xlab = "D50 (mm)", ylim = c(0, 20))
xfit <- seq(min(carhyce_stat_montagne$d50_mm),
            max(carhyce_stat_montagne$d50_mm), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$d50_mm), sd = sd(carhyce_stat_montagne$d50_mm)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$d50_mm) 
lines(xfit, yfit, col = "red", lwd = 2)
h <- hist(carhyce_stat_plaine$d50_mm, col = "lightgreen", main = "Plaine", 
          xlab = "D50 (mm)")
xfit <- seq(min(carhyce_stat_plaine$d50_mm),
            max(carhyce_stat_plaine$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine$d50_mm), sd = sd(carhyce_stat_plaine$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
```

## V√©rification des distributions

```{r, echo=FALSE, fig.align='center'}
# histogram with normal curve
par(mfrow=c(1,2))
h <- hist(carhyce_stat_montagne$d50_mm, col = "lightblue", main = "Montagne", 
          xlab = "D50 (mm)", ylim = c(0, 20))
xfit <- seq(min(carhyce_stat_montagne$d50_mm),
            max(carhyce_stat_montagne$d50_mm), length = 40) 
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne$d50_mm), sd = sd(carhyce_stat_montagne$d50_mm)) 
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne$d50_mm) 
lines(xfit, yfit, col = "red", lwd = 2)
h <- hist(carhyce_stat_plaine$d50_mm, col = "lightgreen", main = "Plaine", 
          xlab = "D50 (mm)")
xfit <- seq(min(carhyce_stat_plaine$d50_mm),
            max(carhyce_stat_plaine$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine$d50_mm), sd = sd(carhyce_stat_plaine$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
```


## Comparaison de moyennes - IC95%

```{r, echo=TRUE, collapse=FALSE}
print(paste0("Taille de l'√©chantillon montagne : ", nrow(carhyce_stat_montagne)))
print(paste0("Taille de l'√©chantillon plaine : ", nrow(carhyce_stat_plaine)))
```
\

[Condition n>30, distribution quelconque]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# mean confidence interval with 95% confidence level
montagne_t_test <- t.test(carhyce_stat_montagne$d50_mm, conf.level = 0.95)
print(paste0("Montagne mean ", round(carhyce_stat_montagne_mean, 2), " IC95% = ", "[", round(montagne_t_test$conf.int[1], 2), " - ", round(montagne_t_test$conf.int[2], 2), "]"))
plaine_t_test <- t.test(carhyce_stat_plaine$d50_mm, conf.level = 0.95)
print(paste0("Plaine mean ", round(carhyce_stat_plaine_mean, 2), " IC95% = ", "[", round(plaine_t_test$conf.int[1], 2), " - ", round(plaine_t_test$conf.int[2], 2), "]"))
```
## Comparaison de moyennes - IC boxplot

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# boxplot with mean, confidence interval and their values
boxplot(carhyce_stat$d50_mm ~ carhyce_stat$montagne_plaine, main = "Granulom√©trie d50", xlab = "", ylab = "Granulom√©trie d50 (mm)", col = c("lightblue", "lightgreen"))
points(1, carhyce_stat_montagne_mean, pch = 19, col = "red")
segments(1, montagne_t_test$conf.int[1], 1, montagne_t_test$conf.int[2], col = "red")
points(2, carhyce_stat_plaine_mean, pch = 19, col = "red")
segments(2, plaine_t_test$conf.int[1], 2, plaine_t_test$conf.int[2], col = "red")
text(1, montagne_t_test$conf.int[2], paste0(round(carhyce_stat_montagne_mean, 2), " [", round(montagne_t_test$conf.int[1], 2), " - ", round(montagne_t_test$conf.int[2], 2), "]"), pos = 3) # 
text(2, plaine_t_test$conf.int[2], paste0(round(carhyce_stat_plaine_mean, 2), " [", round(plaine_t_test$conf.int[1], 2), " - ", round(plaine_t_test$conf.int[2], 2), "]"), pos = 3) # add values of means and confidence intervals
abline(h = 35, col = "red") # add horizontal line at 35 mm
```
## Test de comparaison des variances - F-test {.smaller}

F-test pour comparer les variances :

- $H_0$ : les variances sont √©gales
- $H_1$ : les variances ne sont pas √©gales

```{r, echo=TRUE, collapse=FALSE}
# F-test
var.test(carhyce_stat_montagne$d50_mm, carhyce_stat_plaine$d50_mm)
```
<details>
  <summary>Interpr√©tation</summary>
  La p-value < 0.05, l'hypoth√®se nulle est rejet√©e, les variances des granulom√©tries des rivi√®res de montagne et de plaine sont significativement diff√©rentes.
</details>

## Test de comparaison des moyennes - choix du test {.smaller}

Caract√©ristiques des donn√©es plaine et montagne :

- Deux sous-populations ind√©pendantes (deux zones g√©ographiques diff√©rentes)
- Les variances sont diff√©rentes
- Taille des stations de montagne et de plaine > 30

<details>
  <summary>Test de comparaison des moyennes</summary>

=> Test de Welch non appari√© pour comparer les moyennes de deux √©chantillons ind√©pendants de variance √©gales. (le t.test de R r√©alise un test de variance automatique et r√©alise automatiquement un test de Welch si les variances sont √©gales) :

- $H_0$ : les moyennes des deux √©chantillons sont √©gales.

- $H_1$ : les moyennes des deux √©chantillons sont diff√©rentes.

</details>

## Test de comparaison des moyennes - Welch t-test
    
```{r, echo=TRUE, collapse=FALSE}
# Welch test
t.test(carhyce_stat_montagne$d50_mm, carhyce_stat_plaine$d50_mm,
       var.equal = FALSE, # Welch test
       alternative = "two.sided", # test difference of means
       paired = FALSE, # independant samples
       conf.level = 0.99) # 99% confidence level
```
<details>
  <summary>Interpr√©tation</summary>
  [La p-value est inf√©rieure √† 0.01, l'hypoth√®se nulle est rejet√©e, les moyennes des granulom√©tries des rivi√®res de montagne et de plaine sont significativement diff√©rentes avec un risque de se tromper de 1%.]{style="font-size: 0.7em;"}
</details>

## Petits √©chantillons ou distributions non normales

Etudes des Vosges et des Plaine/collin√©en calcaire.

```{r, echo=TRUE, collapse=FALSE}
# montagne data with only PYRENEES
carhyce_stat_montagne_vosges <- carhyce_stat %>% filter(modele_reference_img == "VOSGES")
# dataset dimension and mean
print(paste0("n = ", dim(carhyce_stat_montagne_vosges)[1]))
print(paste0("Moyenne Vosges = ", mean(carhyce_stat_montagne_vosges$d50_mm, na.rm = TRUE)))
```

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat_plaine_collineen <- carhyce_stat %>% filter(modele_reference_img == "Plaine/collin√©en calcaire")
# dataset dimension and mean
print(paste0("n = ", dim(carhyce_stat_plaine_collineen)[1]))
print(paste0("Moyenne = ", mean(carhyce_stat_plaine_collineen$d50_mm, na.rm = TRUE)))
```

## V√©rification des distributions - Code

```{r, echo=TRUE, eval=FALSE}
# histogram with normal curve
par(mfrow=c(1,2))
h <- hist(carhyce_stat_montagne_vosges$d50_mm, col = "lightblue", main = "Vosges", 
          xlab = "D50 (mm)", ylim = c(0, 20))
xfit <- seq(min(carhyce_stat_montagne_vosges$d50_mm),
            max(carhyce_stat_montagne_vosges$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne_vosges$d50_mm), sd = sd(carhyce_stat_montagne_vosges$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne_vosges$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
h <- hist(carhyce_stat_plaine_collineen$d50_mm, col = "lightgreen", main = "Plaine/collin√©en calcaire", 
          xlab = "D50 (mm)")
xfit <- seq(min(carhyce_stat_plaine_collineen$d50_mm),
            max(carhyce_stat_plaine_collineen$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine_collineen$d50_mm), sd = sd(carhyce_stat_plaine_collineen$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine_collineen$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
```

## V√©rification des distributions

```{r, echo=FALSE, fig.align='center'}
# histogram with normal curve
par(mfrow=c(1,2))
h <- hist(carhyce_stat_montagne_vosges$d50_mm, col = "lightblue", main = "Vosges", 
          xlab = "D50 (mm)", ylim = c(0, 20))
xfit <- seq(min(carhyce_stat_montagne_vosges$d50_mm),
            max(carhyce_stat_montagne_vosges$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_montagne_vosges$d50_mm), sd = sd(carhyce_stat_montagne_vosges$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_montagne_vosges$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
h <- hist(carhyce_stat_plaine_collineen$d50_mm, col = "lightgreen", main = "Plaine/collin√©en calcaire", 
          xlab = "D50 (mm)")
xfit <- seq(min(carhyce_stat_plaine_collineen$d50_mm),
            max(carhyce_stat_plaine_collineen$d50_mm), length = 40)
yfit <- dnorm(xfit, mean = mean(carhyce_stat_plaine_collineen$d50_mm), sd = sd(carhyce_stat_plaine_collineen$d50_mm))
yfit <- yfit * diff(h$mids[1:2]) * length(carhyce_stat_plaine_collineen$d50_mm)
lines(xfit, yfit, col = "red", lwd = 2)
```

## V√©rification des distributions - test de Shapiro-Wilk

```{r, echo=TRUE, collapse=FALSE}
# Shapiro-Wilk test - Vosges
shapiro.test(carhyce_stat_montagne_vosges$d50_mm)
# Shapiro-Wilk test - Plaine/collin√©en calcaire
shapiro.test(carhyce_stat_plaine_collineen$d50_mm)
```
<details>
  <summary>Interpr√©tation</summary>
  Les deux p-value des tests sont sup√©rieur √† 0.05, on peut accepter l'hypoth√®se nulle de normalit√© des distributions m√™me si le peu d'individus rend l'interpr√©tation des graphiques difficiles.
</details>

## Mes variances sont-elles √©gales?

[F-test pour comparer les variances (seuil de significativit√© = 0.05)]{style="font-size: 0.7em;"}

[- $H_0$ : les variances sont √©gales]{style="font-size: 0.7em;"}
[- $H_1$ : les variances sont diff√©rentes]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE}
# F-test
var.test(carhyce_stat_montagne_vosges$d50_mm, carhyce_stat_plaine_collineen$d50_mm)
```
<details>
  <summary>Interpr√©tation</summary>
  La p-value est sup√©rieure √† 0.05, on accepte l'hypoth√®se d'√©galit√© des variances.
</details>

## Comparaison des moyennes - choix du test {.smaller}

Caract√©ristiques Vosges et stations de plaine/collin√©en calcaire : 

- Deux sous-populations ind√©dendantes (deux r√©gions g√©ographiques diff√©rentes).
- Les variances sont √©gales.
- Taille de Vosges > 30, taille de plaine/collin√©en calcaire < 30.
- Les distributions sont consid√©r√©es comme normales.

Hypoth√®ses : 

- $H_0$ : les moyennes des deux granulom√©tries sont √©gales.
- $H_1$ : les moyennes des deux granulom√©tries sont diff√©rentes.

<details>
  <summary>Test de comparaison des moyennes</summary>
  => Test de Student non appari√© √† variance √©gale (seuil de significativit√© de 5%)
</details>

## Comparaison des moyennes - test de Student

```{r, echo=TRUE, collapse=FALSE}
# t test
t.test(carhyce_stat_montagne_vosges$d50_mm, carhyce_stat_plaine_collineen$d50_mm,
       var.equal = TRUE, # equal variance
       alternative = "two.sided", # test difference of means
       paired = FALSE, # independant samples
       conf.level = 0.95) # 95% confidence level
```
<details>
  <summary>Interpr√©tation</summary>
  [p-value > 0.05, on accepte l'hypoth√®se nulle, les moyennes des granulom√©tries sont √©gales. **Ou plus exactement** les donn√©es ne permettent pas de conclure √† une diff√©rence significative.]{style="font-size: 0.7em;"}
</details>

## Comparaison des moyennes - IC95%

Caract√©ristiques Vosges et stations de plaine/collin√©en calcaire : 

- Taille de Vosges > 30 : Th√©or√®me central limite $\sigma \approx s$.
- Taille de plaine/collin√©en calcaire < 30, distribution normale : $\sigma$ remplac√© par $t$ de Student.

::: columns
::: {.column width="50%"}

```{r, echo=TRUE, collapse=FALSE}
# IC95% Vosges
t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)
```

:::
::: {.column width="50%"}

```{r, echo=TRUE, collapse=FALSE}
# IC95% Plaine/collin√©en calcaire
t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)
```
:::
:::

## Comparaison des moyennes - IC95% boxplot {.smaller}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# boxplot with mean, confidence interval and their values
boxplot(carhyce_stat_montagne_vosges$d50_mm, carhyce_stat_plaine_collineen$d50_mm, main = "Granulom√©trie d50", xlab = "", ylab = "Granulom√©trie d50 (mm)", col = c("lightblue", "lightgreen"), names = c("Vosges", "Plaine/collin√©en calcaire"))
points(1, mean(carhyce_stat_montagne_vosges$d50_mm, na.rm = TRUE), pch = 19, col = "red")
segments(1, t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)$conf.int[1], 1, t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)$conf.int[2], col = "red")
points(2, mean(carhyce_stat_plaine_collineen$d50_mm, na.rm = TRUE), pch = 19, col = "red")
segments(2, t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)$conf.int[1], 2, t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)$conf.int[2], col = "red")
text(1, t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)$conf.int[2], paste0(round(mean(carhyce_stat_montagne_vosges$d50_mm, na.rm = TRUE), 2), " [", round(t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)$conf.int[1], 2), " - ", round(t.test(carhyce_stat_montagne_vosges$d50_mm, conf.level = 0.95)$conf.int[2], 2), "]"), pos = 3)
text(2, t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)$conf.int[2], paste0(round(mean(carhyce_stat_plaine_collineen$d50_mm, na.rm = TRUE), 2), " [", round(t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)$conf.int[1], 2), " - ", round(t.test(carhyce_stat_plaine_collineen$d50_mm, conf.level = 0.95)$conf.int[2], 2), "]"), pos = 3)
```
# Analyse multivari√©e / multidimensionnelle

## Principe d'une analyse multivari√©e {.smaller}

J'ai une banane, c'est un objet 3D que je souhaite repr√©senter en 2D. Quel angle choisir pour avoir quelque chose de "reconnaissable" ?

![](./img/banane.png){width="60%" fig-align="center"}

Ma banane de droite est bien plus reconnaissable que celle de gauche. L'angle choisie permet de reconnaitre l'aspect allong√© et courb√© de la banane. La couleur est aussi une information compl√©mentaire utile pour l'interpr√©tation.

L'objectif d'une analyse multivari√©e est de trouver un plan (d√©finis par deux axes) avec le plus d'information possible pour avoir une vue d'ensemble du comportement ou de la structure de nos donn√©es.

::: aside
Cette analogie, l'image et l'explication sont reprises du blog de Lise Vaudor [Lise Vaudor, CNRS, 2021](http://perso.ens-lyon.fr/lise.vaudor/acp/){target="_blank"}
:::

## Analyse multivari√©e / multidimensionnelle {.smaller}

- L'objectif est de synth√©tiser et de structurer l'information contenue dans des donn√©es multidimensionnelles (I individus, K variables) => m√©thode d'exploration des donn√©es.

| Analyse    | Variables                                        | Fonction standard      | Fonction ade4          | Fonctions FactoMineR    |
|----------------|--------------------------------------------------|------------------------|------------------------|-------------------------|
| ACP            | plusieurs variables quantitatives                | stats::princomp()      | ade4::dudi.pca()       | FactoMineR::PCA()       |
| AFC            | deux variables qualitatives                      | MASS::corresp()        | ade4::dudi.coa()       | FactoMineR::CA()        |
| ACM            | plusieurs variables qualitatives                 | MASS::mca()            | ade4::dudi.acm()       | FactoMineR::MCA()       |
| Analyse mixte  | plusieurs variables quantitatives et/ou qualitatives | ‚Äî                      | ade4::dudi.mix()       | FactoMineR::FAMD()      |

::: aside
Source tableau : [Joseph Larmarange 2024](https://larmarange.github.io/guide-R/analyses_avancees/analyse-factorielle.html){target="_blank"}
:::

## Etude des individus et des variables

- Analyse de la variabilit√© entre les individus : 
  - Quels sont leurs caract√©ristiques communes ?
  - Peut-on identifier des profils d'individus ?

- Analyse des variables :
  - Quels sont les liaisons entre les variables ?
  - Peut-on identifier des groupes de variables ?
  
- exemples : 30 individus et 4 variables : 
  - les variables ont 30 dimensions dans l'espace des individus.
  - les individus ont 4 dimensions dans l'espace des variables.
  
## Reprenons nos donn√©es {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2, 
         continuite_ripisylve_rive_gauche,
         continuite_ripisylve_rive_droite,
         score_ripisylve,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         coefficient_de_sinuosite,
         coefficient_rugosite,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2,
         montagne_plaine) # select columns
```

## Analyse en composantes principales (ACP)

**ACP sur tous les individus et toutes les variables :**

```{r, echo=TRUE, collapse=FALSE}
# PCA
pca <- PCA(carhyce_stat[, c("score_ripisylve", "profondeur_moyenne_qb_m", "largeur_mouillee_qb_m", "surface_mouillee_qb_m2", "rayon_hydraulique_qb", "d16_mm", "d50_mm", "d84_mm", "coefficient_de_sinuosite", "coefficient_rugosite", "debit_plein_bord_m3_s", "vitesse_moyenne_qb_m_s", "cote_ligne_energie_qb", "nombre_de_froude_qb", "force_tractrice_qb_n_m2")], 
            ncp = Inf, # number of dimensions
            scale.unit = TRUE, # reduce
            graph = FALSE) # not display graph
print(pca)
```

## ACP - Vocabulaire et information

- **eig** : eigenvalues (valeurs propres)
- **ind** : individus
- **var** : variables
- **coord** : coordonn√©es dans l'espace des individus ou des variables
- **cos2** : qualit√© de repr√©sentation d'un individu ou d'une variable
- **contrib** : contribution d'un individu ou d'une variable au calcul de l'axe

## Centrage et r√©duction

- Les variables sont sonvent exprim√©es dans des unit√©s diff√©rentes, les effets d'√©chelles les rendent difficile √† comparer.

- On les centre : on soustrait la moyenne de chaque variable √† chaque observation.

- On les r√©duit : on divise par l'√©cart-type de chaque variable.

- On obtient des variables centr√©es-r√©duites, qui ont une moyenne nulle et une variance √©gale √† 1.

## Dimension des individus et des variables {.smaller}

- Espace des individus (un individus caract√©ris√© par X variables) : 
```{r, echo=FALSE}
# individus
head(carhyce_stat, n=3)
```

- Espace des variables (une variable caract√©ris√©e par X individus) : 
```{r, echo=FALSE}
# transpose dataframe
carhyce_stat_transposed <- as.data.frame(t(carhyce_stat[, -1]))
head(carhyce_stat_transposed, n=3)
```

## ACP - Analyse des valeurs propres

- Quantit√© de variance expliqu√©e par chaque axe (ou inertie). Deux axes nous permettent de visualiser les donn√©es en 2D.

```{r, echo=TRUE, collapse=FALSE}
head(pca$eig)
```
<details>
  <summary>Interpr√©tation</summary>
  [Le premier axe explique 30% de la variance. Les trois premiers axes permettent d'expliquer 61% de la variance. On va donc s'int√©resser √† ces trois axes pour repr√©senter l'information. Un plan (2D) avec les deux premiers axes permet de repr√©senter 47 % de l'information d'un jeu de donn√©es en 15 dimensions (15 variables quantitatives).]{style="font-size: 0.7em;"}
</details>

## ACP - Analyse graphique des valeurs propres

[Peut-on r√©sumer l'essentiel de l'information avec un nombre r√©duit de dimensions (ou axes) ? => On cherche des "coude" ou points d'inflexion.]{style="font-size: 0.7em;"}

::: columns
::: {.column width="70%"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# Scree plot
fviz_eig(pca, addlabels = TRUE)
```
:::
::: {.column width="30%"}
<details>
  <summary>Interpr√©tation</summary>
  [On trouve 2 points d'inflexion, un apr√®s le premier axe et le second apr√®s le troisi√®me axe. Le premier axe est particuli√®rement int√©ressant, il repr√©sente 30% de l'inertie.]{style="font-size: 0.7em;"}
</details>
:::
:::

## ACP - Crit√®re de Kaiser

[On ne garde que les axes dont la valeur propre est sup√©rieure √† 1 (1 = inertie moyenne si les variables sont centr√©es et r√©duites).]{style="font-size: 0.7em;"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
barplot(pca$eig[,1],xlab = "facteur", ylab = " Inertie (eigenvalue) ", col="blue")
abline(h=1, col="red", lty=2) # add a line at 1
```

## ACP - Contribution au premier axe

[Un axe est compos√© des diff√©rentes variables dans des proportions vari√©es. Quelles sont les variables qui contribuent le plus √† l'inertie du premier axe ? Ou quelles sont les contributions des modalit√©s de l'axe ?]{style="font-size: 0.7em;"}

::: columns
::: {.column width="70%"}


```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
fviz_contrib(pca, choice = "var", axes = 1)
```

:::
::: {.column width="30%"}

<details>
  <summary>Interpr√©tation</summary>
  [Le premier axe se composent principalement de variables de g√©om√©trie avec le d√©bit]{style="font-size: 0.7em;"}
</details>

:::
:::

## ACP - Contribution au deuxi√®me axe

\

::: columns
::: {.column width="70%"}

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
fviz_contrib(pca, choice = "var", axes = 2)
```

:::
::: {.column width="30%"}

<details>
  <summary>Interpr√©tation</summary>
  [Le deuxi√®me axe se compose essentiellement de variables d√©crivant la granulom√©trie et l'√©nergie du cours d'eau]{style="font-size: 0.7em;"}
</details>

:::
:::

## ACP - Interpr√©tation graphique

![](./img/pca.webp){style="width: 100%"}

## ACP - Modalit√©s dans le plan factoriel

::: panel-tabset

### Cercle des corr√©lations

```{r, echo=TRUE, collapse=FALSE}
fviz_pca_var(pca, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
```

### Interpr√©tation

[Les variables bien repr√©sent√©es sur les axes 1 et 2 sont celles des valeurs propres. Nous avons les g√©om√©tries des cours d'eau qui sont aussi fortement corr√©l√©es positivement entre elles (profondeur, rayon, largeur, surface), les indicateurs de la granulom√©trie sont aussi fortement corr√©l√©s positivement entre eux. Nous n'observons pas de corr√©lation entre ces deux groupes. Les indicateurs d'√©nergie des cours d'eau sont moins bien repr√©sent√©s et sont plut√¥t proches des indicateurs de la granulom√©trie √† l'exception de la cote de ligne d'√©nergie.]{style="font-size: 0.7em;"}

:::

## ACP - Les individus dans le plan factoriel

::: panel-tabset

### R√©partitions des individus

```{r, echo=TRUE, collapse=FALSE, fig.height=4}
fviz_pca_ind(pca, geom.ind = "point",
             alpha.ind = 0.3) # densit√© de points superpos√©es
```

### Interpr√©tation

Nous n'observons pas de groupes de stations bien identifi√©s sur les axes 1 et 2. Les stations sont r√©parties de mani√®re homog√®ne dans l'espace des individus.

:::

## ACP Explor

Des variables et/ou individus suppl√©mentaires, non pris en compte dans les calculs, peuvent √™tre ajout√©s pour l'interpr√©tation.

```{r, echo=TRUE, collapse=FALSE}
pca <- PCA(carhyce_stat, 
           quanti.sup = 1, # surface_bv_km2
           quali.sup = c(2,3,4,19), # ripisyle gauche et droite, montagne/plaine
           ncp = Inf, # number of dimensions
           scale.unit = TRUE, # reduce
           graph = FALSE) # not display graph
```
Visualisation avec explor (ouvre une application web) : 
```{r, echo=TRUE, eval=FALSE}
# package explor
explor(pca)
```
## ACP Explor - Graphique

::: panel-tabset

### Individus

```{r, echo=FALSE, collapse=FALSE, fig.align='center', fig.height=7}
res <- explor::prepare_results(pca)
explor::PCA_ind_plot(res, xax = 1, yax = 2, ind_sup = FALSE, lab_var = NULL,
    ind_lab_min_contrib = 0, col_var = "montagne_plaine", labels_size = 9, point_opacity = 0.5,
    opacity_var = NULL, point_size = 28, ellipses = TRUE, transitions = TRUE,
    labels_positions = NULL, xlim = c(-6.59, 8.54), ylim = c(-7.28, 7.86))
```


### Interpr√©tation

[L'ajout de la variable qualitative montagne_plaine permet d'identifier deux profils de stations. Au regard du cercle des corr√©lations, les stations de montagne on tendance √† avoir une granulom√©trie plus grossi√®re et probablement une √©nergie plus forte (vitesse, force tractrice, nombre de froude) que les stations de plaine. Les deux groupes ne sont cependant pas clairement distincts. Les variables de g√©om√©trie ou le d√©bit ne permet pas clairement d'expliquer ces diff√©rences.]{style="font-size: 0.7em;"}

:::

# Classification

## Classification supervis√©e vs non supervis√©e {.smaller}

- **Supervis√©e** : on connait les classes √† l'avance, on cherche √† pr√©dire la classe d'un nouvel individu √† partir de diff√©rentes variables.
  - Exemple : on a une image satellite et on cherche √† identifier les zones urbaines sur la base des valeurs des pixels. On identifie des zones urbains et non urbaines pour entrainer le mod√®le. On se sert du mod√®le pour pr√©dire les zones urbaines sur une nouvelle image.
  - M√©thodes : r√©gression logistique, SVM, Random Forest
- **Non supervis√©e** : on ne connait pas les classes √† l'avance, on cherche √† regrouper les individus en fonction de leurs ressemblances.
  - Exemple : √† partir d'une image satellite, on cherche √† regrouper les pixels en fonction de leurs valeurs et identifier des zones homog√®nes que l'on suppose correspondre √† des occupations du sol diff√©rentes.
  - M√©thodes : K-means, CAH

## Classification ascendante hi√©rarchique (CAH) {.smaller}

- Une m√©thode non supervis√©e qui permet de regrouper des individus en fonction de leurs ressemblances.
- On cherche √† ce que les individus regroup√©s au sein d‚Äôune m√™me classe (homog√©n√©it√© intra-classe) soient le plus semblables possibles tandis que les classes soient le plus dissemblables (h√©t√©rog√©n√©it√© inter-classe).
- La ressemblance ou la dissemblance entre les individus est mesur√©e √† l'aide d'une matrice distances entre chaque individus pris deux √† deux. Plus la distance est faible, plus les individus sont semblables.
- La CAH part des individus (ascendante) et les regroupe progressivement en classes de plus en plus grandes (hi√©rarchique) => dendrogramme.

::: aside
Voir [le guide de Joseph Larmarange IRD, 2024](https://larmarange.github.io/guide-R/analyses_avancees/classification-ascendante-hierarchique.html){target="_blank"} ou [Analyse-R](https://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.html){target="_blank"}
:::

## Principes de la CAH

::: {.r-stack}

- On commence par consid√©rer chaque individu comme une classe √† part enti√®re.
- On regroupe les deux individus les plus proches pour former une nouvelle classe.
- On r√©p√®te l'op√©ration jusqu'√† ce que tous les individus soient regroup√©s dans une seule classe.
- On obtient un dendrogramme qui permet de visualiser les regroupements successifs.

![](./img/cah_step1.webp){.fragment fragment-index="1" .fade-in-then-out style="position: absolute; top: 10%; left:0; width: 100%;"}
![](./img/cah_step2.webp){.fragment fragment-index="2" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step3.webp){.fragment fragment-index="3" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step4.webp){.fragment fragment-index="4" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step5.webp){.fragment fragment-index="5" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step6.webp){.fragment fragment-index="6" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step7.webp){.fragment fragment-index="7" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
![](./img/cah_step8.webp){.fragment fragment-index="8" .fade-in-then-out style="position: absolute; top: 10%; left: 0; width: 100%;"}
:::


## Reprenons nos donn√©es {.smaller}

```{r, echo=TRUE, collapse=FALSE}
carhyce_stat <- carhyce %>% 
  # select the last date for each station
  group_by(code_station) %>% # group by station
  filter(date_realisation == max(date_realisation)) %>% # select the last date by group
  ungroup() %>%  # ungroup data
  mutate(surface_bv_km2 = ifelse(surface_bv_km2 %in% boxplot.stats(surface_bv_km2)$out, NA, surface_bv_km2),
         score_ripisylve = ifelse(score_ripisylve %in% boxplot.stats(score_ripisylve)$out, NA, score_ripisylve),
         profondeur_moyenne_qb_m = ifelse(profondeur_moyenne_qb_m %in% boxplot.stats(profondeur_moyenne_qb_m)$out, NA, profondeur_moyenne_qb_m),
         largeur_mouillee_qb_m = ifelse(largeur_mouillee_qb_m %in% boxplot.stats(largeur_mouillee_qb_m)$out, NA, largeur_mouillee_qb_m),
         surface_mouillee_qb_m2 = ifelse(surface_mouillee_qb_m2 %in% boxplot.stats(surface_mouillee_qb_m2)$out, NA, surface_mouillee_qb_m2),
         rayon_hydraulique_qb = ifelse(rayon_hydraulique_qb %in% boxplot.stats(rayon_hydraulique_qb)$out, NA, rayon_hydraulique_qb),
         d16_mm = ifelse(d16_mm %in% boxplot.stats(d16_mm)$out, NA, d16_mm),
         d50_mm = ifelse(d50_mm %in% boxplot.stats(d50_mm)$out, NA, d50_mm),
         d84_mm = ifelse(d84_mm %in% boxplot.stats(d84_mm)$out, NA, d84_mm),
         coefficient_de_sinuosite = ifelse(coefficient_de_sinuosite %in% boxplot.stats(coefficient_de_sinuosite)$out, NA, coefficient_de_sinuosite),
         coefficient_rugosite = ifelse(coefficient_rugosite %in% boxplot.stats(coefficient_rugosite)$out, NA, coefficient_rugosite),
         debit_plein_bord_m3_s = ifelse(debit_plein_bord_m3_s %in% boxplot.stats(debit_plein_bord_m3_s)$out, NA, debit_plein_bord_m3_s),
         vitesse_moyenne_qb_m_s = ifelse(vitesse_moyenne_qb_m_s %in% boxplot.stats(vitesse_moyenne_qb_m_s)$out, NA, vitesse_moyenne_qb_m_s),
         cote_ligne_energie_qb = ifelse(cote_ligne_energie_qb %in% boxplot.stats(cote_ligne_energie_qb)$out, NA, cote_ligne_energie_qb),
         nombre_de_froude_qb = ifelse(nombre_de_froude_qb %in% boxplot.stats(nombre_de_froude_qb)$out, NA, nombre_de_froude_qb),
         force_tractrice_qb_n_m2 = ifelse(force_tractrice_qb_n_m2 %in% boxplot.stats(force_tractrice_qb_n_m2)$out, NA, force_tractrice_qb_n_m2)) %>% # replace outliers by NA by Interquartile range (IQR) from boxplot function
  mutate(montagne_plaine = ifelse(modele_reference_img %in% c("ALPES INTERNES", "CEVENNES", "CORSE", "JURA-PREALPES DU NORD", "MASSIF CENTRAL NORD", "MASSIF CENTRAL SUD", "Montagne volcanique des DOM", "PREALPES DU SUD", "PYRENEES"), "montagne", "plaine")) %>% # try to classify in two category, montagne and plaine
  # select columns
  select(surface_bv_km2,
         profondeur_moyenne_qb_m,
         largeur_mouillee_qb_m,
         surface_mouillee_qb_m2,
         rayon_hydraulique_qb,
         d16_mm,
         d50_mm,
         d84_mm,
         debit_plein_bord_m3_s,
         vitesse_moyenne_qb_m_s,
         cote_ligne_energie_qb,
         nombre_de_froude_qb,
         force_tractrice_qb_n_m2) %>%  # select columns
  na.omit() # remove NA
```

## Normalisation des donn√©es {.smaller}

- Toujours avoir une √©tape de description des donn√©es (distribution, qualit√©, graph de corr√©lation, etc.).

- Homog√©n√©isation des donn√©es pour √©viter les effets d'√©chelle (unit√©s diff√©rentes) et que les variables √† forte variance soit pr√©pond√©rante dans les r√©sultats.

Transformation de Milligan & Cooper (utilis√©e pour la suite, donne une meilleur d√©couvertd de cluster)
```{r, echo=TRUE, collapse=FALSE}
# Milligan & Cooper transformation function
normalize_MC <- function(x) {
  return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}
# normalize data
carhyce_stat_mc<-as.data.frame(lapply(carhyce_stat, normalize_MC))
```

\

Transformation z-score (centrage-r√©duction)
```{r, echo=TRUE, collapse=FALSE}
# z-score transformation
carhyce_stat_z <- scale(carhyce_stat, center = TRUE, scale = TRUE)
```

## La matrice de distance

Calul de la distance entre chaque individu.

- Plusieurs m√©thode de calcul de distance : 
  - **Variables quantitative** : euclidienne, manhattan, Gower, etc.
  - **Variables qualitative** : Gower, $\phi^2$, etc.

```{r, echo=TRUE, collapse=FALSE}
# Euclidean distance
dist_euclid <- dist(carhyce_stat_mc, method = "euclidean")
```

## M√©thode d'aggr√©gation {.smaller}

Comment regrouper des classes entres elles ou calculer la distance entre deux classes ?

- **Saut maximum (ou complete linkage)** : distance maximum entre deux individus de deux classes. Tend √† cr√©er des classes de diam√®tre √©quivalent, sensible aux individus hors normes.
- **Saut minimum (ou single linkage)** : distance minimum entre deux individus de deux classes. Permet de traiter des formes allong√©es mais peut avoir des effets de cha√Æne et regrouper deux classes √©loign√©es reli√©es par une cha√Æne d'individus.
- **Distance moyenne (ou average linkage)** : moyenne des distances entre tous les individus de deux classes. Moins sensible aux bruits, tend √† cr√©er des classes de m√™me variance.
- **Distance des barycentre (ou centroid linkage)** : distance entre les barycentres des deux classes. Peu sensible au bruit mais moins pr√©cise.
 - **Distance de Ward** : minimise l'inertie (ou  la variance) intra-classe ou  maximise l'intertie inter-classe (diff√©rences entre les classes). Une m√©thode tr√®s utilis√©e, peu sensible aux bruits et aux valeurs extr√™mes, tend √† cr√©er des classes sph√©riques et de m√™me effectifs.
 
::: aside
 Pour aller plus loin, voir Data Mining et Statistique d√©cisionnelle (2017), St√©phane Tuff√©ry, Editions Technip et l'article Hierarchical Clustering de Fatih Karabiber sur [https://www.learndatasci.com](https://www.learndatasci.com/glossary/hierarchical-clustering/){target="_blank"}
:::

## Agrr√©gation et dendrogramme
  
```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
# Ward method
hc <- hclust(dist_euclid, method = "ward.D2")
# Dendrogram
plot(hc, hang = -1, cex = 0.6, main = "Dendrogramme CAH")
```
## Nombre de classes

- Evaluation graphique sur le dendrogramme.
- Repr√©sentation des pertes d'inertie inter-classe (mesure la s√©paration entre chaque classe). Plus le saut est grand plus la distance entre les clusters fusionn√©s est grande.

## Nombre de classes - Inertie

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
v <- sort(hc$height,decreasing=T)
plot(1:length(v),v,type = "s", xlab = "Nombre de classes", ylab = "Inertie", xlim = c(0, 30),
     xaxt = "n")
axis(1, at = seq(1, 30, by = 1), las=2)
```

## D√©couper les classes

```{r, echo=TRUE, collapse=FALSE, fig.align='center'}
plot(hc, labels = FALSE, main = "Partition en 2, 5 ou 8 classes", xlab = "", ylab = "", sub = "", axes = FALSE, hang = -1)
rect.hclust(hc, 2, border = "green3")
rect.hclust(hc, 5, border = "red3")
rect.hclust(hc, 8, border = "blue3")
```

```{r, echo=TRUE, collapse=FALSE}
# cut dendrograme in 5 classes
hc_gp <- cutree(hc,k=5)
```

## Interpr√©tation CAH

- Quelles sont les distributions des variables dans chaque classe ?
- Quelles sont les caract√©ristiques des individus dans chaque classe ?
- Quelles sont les caract√©ristiques des classes ?

```{r, echo=TRUE, collapse=FALSE, fig.align='center', eval=FALSE}
# box plot each class for each variable
carhyce_stat$group <- as.factor(hc_gp)
carhyce_stat %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = group, y = value, fill = group)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Interpr√©tation CAH - boxplot variables

```{r, echo=FALSE, collapse=FALSE, fig.align='center'}
# box plot each class for each variable
carhyce_stat$group <- as.factor(hc_gp)
carhyce_stat %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = group, y = value, fill = group)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Interpr√©tation CAH - boxplot classes

```{r, echo=TRUE, collapse=FALSE, fig.align='center', fig.width=15}
# variables boxplots for class 2 only
carhyce_stat %>%
  filter(group == 2) %>%
  gather(key = "variable", value = "value", -group) %>%
  ggplot(aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() + theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Interpr√©tation CAH - ACP

```{r, echo=TRUE, collapse=FALSE}
# PCA
pca <- PCA(carhyce_stat, ncp = Inf, scale.unit = TRUE, graph = FALSE,
            quali.sup = 14) # illustrative group variable
# explor(pca)
```

```{r, echo=FALSE, collapse=FALSE, fig.align='center', fig.height=7}
res <- explor::prepare_results(pca)
explor::PCA_ind_plot(res, xax = 1, yax = 2, ind_sup = FALSE, lab_var = NULL,
    ind_lab_min_contrib = 0, col_var = "group", labels_size = 9, point_opacity = 0.5,
    opacity_var = NULL, point_size = 64, ellipses = TRUE, transitions = TRUE,
    labels_positions = NULL, xlim = c(-6.76, 11.9), ylim = c(-8.72, 9.95))
```

## Classification K





